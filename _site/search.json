[
  {
    "objectID": "posts/A3 - Veg vs Non-Veg in Tips/index.html",
    "href": "posts/A3 - Veg vs Non-Veg in Tips/index.html",
    "title": "A3 - Veg vs Non-Veg in Tips",
    "section": "",
    "text": ".\nIn and around SMI campus, a person was found.\nQuestions regarding their preference in food (Non-Veg/Veg) and how much they leave in tips were asked.\nA coin was flipped.\nThere was a 50% chance that that person contributed to this data sample!\n.\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula)\nlibrary(infer) \n\n\nAttaching package: 'infer'\n\nThe following objects are masked from 'package:mosaic':\n\n    prop_test, t_test\n\nlibrary(broom) \nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(gt)\nlibrary(DT)\n\n."
  },
  {
    "objectID": "posts/A3 - Veg vs Non-Veg in Tips/index.html#introduction",
    "href": "posts/A3 - Veg vs Non-Veg in Tips/index.html#introduction",
    "title": "A3 - Veg vs Non-Veg in Tips",
    "section": "",
    "text": ".\nIn and around SMI campus, a person was found.\nQuestions regarding their preference in food (Non-Veg/Veg) and how much they leave in tips were asked.\nA coin was flipped.\nThere was a 50% chance that that person contributed to this data sample!\n.\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula)\nlibrary(infer) \n\n\nAttaching package: 'infer'\n\nThe following objects are masked from 'package:mosaic':\n\n    prop_test, t_test\n\nlibrary(broom) \nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(gt)\nlibrary(DT)\n\n."
  },
  {
    "objectID": "posts/A3 - Veg vs Non-Veg in Tips/index.html#reading-and-examining-data",
    "href": "posts/A3 - Veg vs Non-Veg in Tips/index.html#reading-and-examining-data",
    "title": "A3 - Veg vs Non-Veg in Tips",
    "section": "Reading and Examining Data",
    "text": "Reading and Examining Data\n.\n\ntips &lt;- read_csv(\"../../Data/tips.csv\")\n\nRows: 60 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Name, Gender, Preference\ndbl (1): Tip\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntips %&gt;% glimpse()\n\nRows: 60\nColumns: 4\n$ Name       &lt;chr&gt; \"Aanya\", \"Adit\", \"Aditi\", \"Akash\", \"Akshita\", \"Anandita\", \"…\n$ Gender     &lt;chr&gt; \"Female\", \"Male\", \"Female\", \"Male\", \"Female\", \"Female\", \"Fe…\n$ Preference &lt;chr&gt; \"Veg\", \"Veg\", \"Veg\", \"Non-veg\", \"Non-veg\", \"Non-veg\", \"Non-…\n$ Tip        &lt;dbl&gt; 0, 0, 20, 0, 0, 0, 20, 35, 40, 0, 0, 0, 0, 0, 0, 0, 20, 0, …\n\n\n.\n\ndatatable(tips, options = list(pageLength = 10))\n\n\n\n\n\n.\n\ntips %&gt;% inspect()\n\n\ncategorical variables:  \n        name     class levels  n missing\n1       Name character     60 60       0\n2     Gender character      2 60       0\n3 Preference character      2 60       0\n                                   distribution\n1 Aanya (1.7%), Adit (1.7%) ...                \n2 Female (50%), Male (50%)                     \n3 Non-veg (50%), Veg (50%)                     \n\nquantitative variables:  \n  name   class min Q1 median Q3 max     mean       sd  n missing\n1  Tip numeric   0  0      0 20 100 11.16667 17.83556 60       0\n\n\n.\n\ntips %&gt;% skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n60\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nName\n0\n1\n4\n9\n0\n60\n0\n\n\nGender\n0\n1\n4\n6\n0\n2\n0\n\n\nPreference\n0\n1\n3\n7\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nTip\n0\n1\n11.17\n17.84\n0\n0\n0\n20\n100\n▇▁▁▁▁\n\n\n\n\n\n.\n\nData Dictionary\nThere are 60 rows and 4 columns in this data sample.\n.\n\nName: A qualitative variable indicating the name of each participant\nGender: A qualitative variable indicating the gender of each participant, either male or female. Out of the 60 participants, there are a total of 30 males, 15 of whom prefer Non-Veg and 15 of whom prefer Veg.\nPreference: A qualitative variable that describes the food preference of every participant, either Veg or Non-Veg\nTips: The only quantitative variable in this data sample, describing the value that each participant leaves as a tip.\n\n."
  },
  {
    "objectID": "posts/A3 - Veg vs Non-Veg in Tips/index.html#charting-data",
    "href": "posts/A3 - Veg vs Non-Veg in Tips/index.html#charting-data",
    "title": "A3 - Veg vs Non-Veg in Tips",
    "section": "Charting Data",
    "text": "Charting Data\n.\n\ntips %&gt;%\n  gf_density(\n    ~ Tip,\n    fill = ~ Preference,\n    alpha = 0.5,\n    title = \"Tips Score Densities\",\n    subtitle = \"Veg vs Non-Veg\"\n  )\n\n\n\n\n\n\n\n##\ntips %&gt;%\n  gf_boxplot(\n    Tip ~ Preference,\n    fill = ~ Preference,\n    alpha = 0.5,\n    title = \"Tips Score Box Plots\",\n    subtitle = \"Veg vs Non-Veg\"\n  ) \n\n\n\n\n\n\n\n##\ntips %&gt;% count(Preference)\n\n# A tibble: 2 × 2\n  Preference     n\n  &lt;chr&gt;      &lt;int&gt;\n1 Non-veg       30\n2 Veg           30\n\ntips %&gt;% \n  group_by(Preference) %&gt;% \n  summarise(mean = mean(Tip))\n\n# A tibble: 2 × 2\n  Preference  mean\n  &lt;chr&gt;      &lt;dbl&gt;\n1 Non-veg     10  \n2 Veg         12.3\n\n\n.\n\nThe data has an equal number of Non-Vegetarians and Vegetarians. As the sample sizes are equal, the means of both samples are comparable.\nThe mean value of tips given by Vegetarians (12.33 Rs.) is ever so slightly higher than the mean value of tips given by Non-Vegetarians (10.00Rs)\nThough the density graphs for both groups look quite different the box plots are practically identical. The overlap and peaks of the density graph indicates that both Vegetarians and Non-Vegetarians usually tip in the 0-10 range. It tells us that Non-Vegetarians also have the tendency to tip in the 15-20 range, as there is a peak in the graph there. Both distributions taper off at the 50rs mark, suggesting that neither group tips higher than 60rs. However, the distributions of Vegetarians picks up slightly in the end, suggesting an outlier.\nThe box-plots showcase that both Non-Vegetarians and Vegetarians have similar central tendencies as their medians, inter-quartile ranges and whiskers suggest that both groups have similar tipping ranges excluding outliers. The boxplot also confirms the presence of an outlier at the 100Rs mark in the Vegetarian group. It’s right skew indicated that the mean is bigger than the median, which holds true.\nThis data set is the perfect example of why both box-plots and density graphs are required to completely visualize and represent data. While the box-plot is a great way to view central tendencies at a glance, the distributions presented in the density graphs indicated the nuances of the data that the box-plots may not recognize."
  },
  {
    "objectID": "posts/A3 - Veg vs Non-Veg in Tips/index.html#research-question",
    "href": "posts/A3 - Veg vs Non-Veg in Tips/index.html#research-question",
    "title": "A3 - Veg vs Non-Veg in Tips",
    "section": "Research Question",
    "text": "Research Question\nIs there a difference in the way that Vegetarians and Non-Vegetarians in and around SMI Campus tip?\n\nHypothesis\nCase 0 - Null Hypothesis:\n\nmean(Vegetarian Tips) = mean(Non-Vegetarian Tips)\n\nCase 1:\n\nmean(Vegetarian Tips) ≠ mean(Non-Vegetarian Tips)\n\n.\n\n\nChecking for Normalcy\n\nAre the data distributions normal?\n\n.\n\ntips %&gt;% \n  gf_density( ~ Tip,\n            fill = ~ Preference,\n            alpha = 0.5,\n            title = \"Tips across Veg and Non-Veg\") %&gt;% \n  gf_facet_grid(~Preference) %&gt;% \n  gf_fitdistr(dist = \"dnorm\")\n\n\n\n\n\n\n\n##\n\ntips %&gt;% \n  gf_qqline(~ Tip,\n          color = ~ Preference,\n          title = \"Tips...are they Normally Distributed?\") %&gt;% \n  gf_qq(~ Tip,\n          color = ~ Preference,\n          title = \"Tips...are they Normally Distributed?\") %&gt;% \n  gf_facet_wrap(~ Preference)\n\n\n\n\n\n\n\n##\n\nveg_tips &lt;- tips %&gt;% \n  filter( Preference == \"Veg\") %&gt;% \n  select(Tip)\n##\n\nnon_veg_tips &lt;- tips %&gt;% \n  filter( Preference == \"Non-veg\")\n##\n\n.\n\nIn a Q-Q graph, the x-axis indicates the theoretical distribution of the quantiles if the data was normally distributed around the mean, and the y-axis indicates the actual distribution of the data sample. The dotted slope line provides a reference to check how closely the sample data matches its theoretical distribution.\n\n.\n\nAt a glance the density graphs show that in both groups, the data is quite far from being a normal distribution, as indicated by the black line.\n\n\n\nIn both the Vegetarian and Non-Vegetarian Distributions, it is clear to see that the sample data does not follow the theoretical data. This is a big indicator that the sample data is not normally distributed.\nThe sample data has points plotted primarily at the 0 mark, and next at the 20 mark in both groups, even if the number of points at those levels many vary per group. This graph confirms the inferences from the box plot - the box has a right-skew, with the median at 0. Most data points fall in the lower quartile range, and outliers lie on the upper ranges.\n.\n\n\nshapiro.test(veg_tips$Tip)\n\n\n    Shapiro-Wilk normality test\n\ndata:  veg_tips$Tip\nW = 0.6286, p-value = 1.661e-07\n\nshapiro.test(non_veg_tips$Tip)\n\n\n    Shapiro-Wilk normality test\n\ndata:  non_veg_tips$Tip\nW = 0.71661, p-value = 2.747e-06\n\n\n.\n\nThe value of W calculated by the Shapiro test (always lying between 0-1) doesn’t seem to be high enough to indicate a normal distribution. The p-value, which tells one the chances of a normal distribution are quite low for both groups, confirming the previous inferences.\n\n.\n\n\nChecking for Variance\n\nAre the data variances similar?\n\n.\n\nvar.test(Tip ~ Preference, data = tips, \n         conf.int = TRUE, conf.level = 0.95) %&gt;% \n  broom::tidy()\n\nMultiple parameters; naming those columns num.df, den.df\n\n\n# A tibble: 1 × 9\n  estimate num.df den.df statistic p.value conf.low conf.high method alternative\n     &lt;dbl&gt;  &lt;int&gt;  &lt;int&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;      \n1    0.346     29     29     0.346 0.00554    0.165     0.726 F tes… two.sided  \n\n\n.\n\n## checking which group comes first\ntips %&gt;% \n  mutate( Preference = as_factor(Preference))\n\n# A tibble: 60 × 4\n   Name     Gender Preference   Tip\n   &lt;chr&gt;    &lt;chr&gt;  &lt;fct&gt;      &lt;dbl&gt;\n 1 Aanya    Female Veg            0\n 2 Adit     Male   Veg            0\n 3 Aditi    Female Veg           20\n 4 Akash    Male   Non-veg        0\n 5 Akshita  Female Non-veg        0\n 6 Anandita Female Non-veg        0\n 7 Ananya   Female Non-veg       20\n 8 Anaya    Female Veg           35\n 9 Anhuya   Female Veg           40\n10 Ankit    Male   Non-veg        0\n# ℹ 50 more rows\n\n  levels(tips$Preference)\n\nNULL\n\n\n.\n\nThe estimate value of 0.345 indicates that the variance in tips of Non-Vegetarians is around 36.56% of the variance of Vegetarian tips. This means that the variances of both groups are quite different.\nThis is supported by the p-value which tells the chances of similar variance, by testing the null hypothesis. The value provided is quite low, suggesting variances that are not similar.\n\n.\n\n##\nqf(0.345,29,29)\n\n[1] 0.8611538\n\n\n.\n\nAs the value returned by the qf() function is greater than the value of the estimate from the var.test, it means that the Case 0, or the null hypothesis can’t be rejected, i.e, the mean of Vegetarian tips may very well be equal to the mean of the Non-Vegetarian tips.\n\n.\n\n\nObserved and Test Statistics\n\nAs the both groups in data sample are not normally distributed and have significant variance, the parametric t.test cannot be used, and the wilcox.testand linear model with ranked data should be used instead. Finally, a permutation test will also be done.\n\n.\n\n## using the test statistic of difference in means. Is it non zero?\nobs_diff_tips &lt;- diffmean(Tip ~ Preference, data = tips) \nobs_diff_tips\n\ndiffmean \n2.333333 \n\n## yes.\n\n.\n."
  },
  {
    "objectID": "posts/A3 - Veg vs Non-Veg in Tips/index.html#inference",
    "href": "posts/A3 - Veg vs Non-Veg in Tips/index.html#inference",
    "title": "A3 - Veg vs Non-Veg in Tips",
    "section": "Inference",
    "text": "Inference\n.\n\nwilcox.test\n.\n\nwilcox.test(Tip ~ Preference, data = tips, \n            conf.int = TRUE, \n            conf.level = 0.95) %&gt;% \n  broom::tidy()\n\nWarning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\ncompute exact p-value with ties\n\n\nWarning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\ncompute exact confidence intervals with ties\n\n\n# A tibble: 1 × 7\n   estimate statistic p.value   conf.low   conf.high method          alternative\n      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;      \n1 0.0000372       463   0.833 -0.0000335 0.000000989 Wilcoxon rank … two.sided  \n\n\n.\n\nthe p-value of 0.8327 is greater than that of 0.05, and hence, Case 0, the null hypothesis cannot be rejected.\n\n.\n\n\nLinear Model\n.\n\nlm(rank(Tip) ~ Preference, \n   data = tips) %&gt;% \n  broom::tidy(conf.int = TRUE,\n              conf.level = 0.95)\n\n# A tibble: 2 × 7\n  term          estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)     30.9        2.81    11.0   8.04e-16    25.3      36.6 \n2 PreferenceVeg   -0.867      3.98    -0.218 8.28e- 1    -8.83      7.09\n\n\n.\n\nOnce again here, the p-value of 0.8282 (for PreferenceVeg) is greater than that of 0.05, and hence, Case 0, the null hypothesis cannot be rejected.\n\n.\n\n\nPermutation Test\n.\n\n## taking the test statistic after each shuffle of preference, 4999 times\n\nnull_dist_tips &lt;- \n  do(4999) * diffmean(data = tips, Tip ~ shuffle(Preference))\n##\ndatatable(null_dist_tips, options = list(pageLength = 10))\n\n\n\n\n\n.\n\nnull_dist_tips %&gt;% \n  gf_histogram(~diffmean,\n               bins = 25) %&gt;% \n    gf_vline(xintercept = obs_diff_tips,\n             color = \"red\",\n             linewidth = 1,\n             title = \"Null Distribution by Permutation\",\n             subtitle = \"Histogram\") %&gt;% \n  gf_labs( x = \"Difference in Means\")\n\n\n\n\n\n\n\n##\nnull_dist_tips %&gt;% \ngf_ecdf( ~ diffmean, \n        linewidth = 1) %&gt;%\n  gf_vline(xintercept = obs_diff_tips, \n           colour = \"red\", linewidth = 1,\n           title = \"Null Distribution by Permutation\", \n           subtitle = \"Cumulative Density\") %&gt;% \n  gf_labs(x = \"Difference in Means\")\n\n\n\n\n\n\n\n\n.\n\nThe first graph describes the observed difference in means from the permutation test in comparison the the distribution of the permuted differences. Since the observed difference in means falls within the distribution of permuted means, it suggests that there is not enough evidence to conclude that there is a real difference in the tips that Vegetarians and Non-Vegetarians leave.\nEssentially it means (haha, see what I did there) that the observed difference could have arisen due to random chance under the null hypothesis. It’s not so special!\n\n.\n\nprop1(~ diffmean &lt;= obs_diff_tips, data = null_dist_tips)\n\nprop_TRUE \n   0.6932 \n\n\n.\n\nthe prop1() function calculates the proportion of values in the 4999 permutations that are as much or less than obs_diff_tips = 2.3333. In this case, 69.34% of the permutations are the same or less, suggesting that the null hypothesis might as well be true.\n\n.\n\n\nAll Tests Together\n.\n\nwilcox.test(Tip ~ Preference, data = tips, \n            conf.int = TRUE, \n            conf.level = 0.95) %&gt;% \n  broom::tidy() %&gt;% \n  gt() %&gt;%\n  tab_style(\n    style = list(cell_fill(color = \"violet\"), cell_text(weight = \"bold\")),\n    locations = cells_body(columns = p.value)) %&gt;% \n  tab_header(title = \"wilcox.test\")\n\nWarning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\ncompute exact p-value with ties\n\n\nWarning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\ncompute exact confidence intervals with ties\n\n\n\n\n\n\n\n\nwilcox.test\n\n\nestimate\nstatistic\np.value\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n3.723443e-05\n463\n0.8326761\n-3.353485e-05\n9.890472e-07\nWilcoxon rank sum test with continuity correction\ntwo.sided\n\n\n\n\n\n\n## \n\nlm(rank(Tip) ~ Preference, \n   data = tips) %&gt;% \n  broom::tidy(conf.int = TRUE,\n              conf.level = 0.95) %&gt;% \n  gt() %&gt;%\n  tab_style(\n    style = list(cell_fill(color = \"violet\"),cell_text(weight = \"bold\")),\n    locations = cells_body(columns = p.value)) %&gt;% \n  tab_header(title = \"Linear Model with Ranked Data\")\n\n\n\n\n\n\n\nLinear Model with Ranked Data\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n30.9333333\n2.811893\n11.0008920\n8.040166e-16\n25.304718\n36.561949\n\n\nPreferenceVeg\n-0.8666667\n3.976617\n-0.2179407\n8.282403e-01\n-8.826731\n7.093398\n\n\n\n\n\n\n\n.\nThis last table highlights the results of the wilcox.test and the linear model by ranks. In both tables, the purple boxes signify the p-values that describe the probability of accepting the null hypothesis - both pretty high in the 80-something percents.\n.\n."
  },
  {
    "objectID": "posts/A3 - Veg vs Non-Veg in Tips/index.html#conclusion",
    "href": "posts/A3 - Veg vs Non-Veg in Tips/index.html#conclusion",
    "title": "A3 - Veg vs Non-Veg in Tips",
    "section": "Conclusion",
    "text": "Conclusion\nThe null hypothesis rings true! There is no (statistically significant) difference in the means, or rather,\n\nmean(Vegetarian Tips) = mean(Non-Vegetarian Tips)\n\n.\nAnd so,\nFor this data sample that was collected in SMI, that describes how much students categorized as vegetarians and non-vegetarians leave in tips, we can conclude that there is no difference in their tipping habits - i.e, the value of the tip left by a person is not related to if they are vegetarian or non-vegetarian."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data-as-Material-Class",
    "section": "",
    "text": "(5) A2: Case Study 2\n\n\n\n\n\n\n\n\n\n\n\nVasantha M\n\n\n\n\n\n\n\n\n\n\n\n\n(6) A2 - Case Study 3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(4) A2 - Case Study 1\n\n\n\n\n\n\n\n\n\n\n\nVasantha M\n\n\n\n\n\n\n\n\n\n\n\n\n(9) A3 - B.FA vs B.Des vs B.Voc\n\n\n\n\n\n\n\n\n\n\n\nVasantha M\n\n\n\n\n\n\n\n\n\n\n\n\n(8) A3 - Chhota Bheem vs Doremon vs Dragon Tales\n\n\n\n\n\n\n\n\n\n\n\nVasantha M\n\n\n\n\n\n\n\n\n\n\n\n\n(10) A3 - Gals vs Guys in Spending\n\n\n\n\n\n\n\n\n\n\n\nVasantha M\n\n\n\n\n\n\n\n\n\n\n\n\n(7) A3 - Veg vs Non-Veg in Tips\n\n\n\n\n\n\n\n\n\n\n\nVasantha M\n\n\n\n\n\n\n\n\n\n\n\n\n(1) Day 1: Hello Universe\n\n\n\n\n\n\n\n\n\n\n\nVasantha M\n\n\n\n\n\n\n\n\n\n\n\n\n(2) Day 2: Summaries\n\n\n\n\n\n\n\n\n\n\n\nVasantha M\n\n\n\n\n\n\n\n\n\n\n\n\n(3) Day 3: Counts\n\n\n\n\n\n\n\n\n\n\n\nVasantha M\n\n\n\n\n\n\n\n\n\n\n\n\nDay 4: Quantities\n\n\n\n\n\n\n\n\n\n\n\nVasantha M\n\n\n\n\n\n\n\n\n\n\n\n\nDay 5: Groups\n\n\n\n\n\n\n\n\n\n\n\nVasantha M\n\n\n\n\n\n\n\n\n\n\n\n\nDay 5: Change\n\n\n\n\n\n\n\n\n\n\n\nVasantha M\n\n\n\n\n\n\n\n\n\n\n\n\nDay 6: Stats Theory\n\n\n\n\n\n\n\n\n\n\n\nVasantha M\n\n\n\n\n\n\n\n\n\n\n\n\nDay 7: Comparing Multiple Means with ANOVA\n\n\n\n\n\n\n\n\n\n\n\nVasantha M\n\n\n\n\n\n\n\n\n\n\n\n\nDay 8: Stats Theory Proportions\n\n\n\n\n\n\n\n\n\n\n\nVasantha M\n\n\n\n\n\n\n\n\n\n\n\n\n(11) And Finally…..\n\n\n\n\n\n\n\n\n\n\n\nVasantha M\n\n\n\n\n\n\n\n\n\n\n\n\nOnline Session - Maps\n\n\n\n\n\n\n\n\n\n\n\nVasantha M\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Day 7/index.html",
    "href": "posts/Day 7/index.html",
    "title": "Day 7: Comparing Multiple Means with ANOVA",
    "section": "",
    "text": ".\n\n\n.\n\n\n\n#| label: setup}\n\nlibrary(tidyverse) # Tidy data processing\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggformula) # Formula based plots\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(mosaic) # Data inspection and Statistical Inference\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(broom) # Tidy outputs from Statistical Analyses\nlibrary(infer) # Statistical Inference, Permutation/Bootstrap\n\n\nAttaching package: 'infer'\n\nThe following objects are masked from 'package:mosaic':\n\n    prop_test, t_test\n\nlibrary(patchwork) # Arranging Plots\nlibrary(ggprism) # Interesting Categorical Axes\nlibrary(supernova) # Beginner-Friendly ANOVA Tables\n\n\nAttaching package: 'supernova'\n\nThe following object is masked from 'package:scales':\n\n    number\n\n\n.\n.\n\n\n\n\n\n## Calling Data\nfrogs_orig &lt;- read_delim(file =\"../../Data/frogs.csv\", delim = \",\")\n\nRows: 60 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (4): Frogspawn sample id, Temperature13, Temperature18, Temperature25\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nfrogs_orig\n\n# A tibble: 60 × 4\n   `Frogspawn sample id` Temperature13 Temperature18 Temperature25\n                   &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n 1                     1            24            NA            NA\n 2                     2            NA            21            NA\n 3                     3            NA            NA            18\n 4                     4            26            NA            NA\n 5                     5            NA            22            NA\n 6                     6            NA            NA            14\n 7                     7            27            NA            NA\n 8                     8            NA            22            NA\n 9                     9            NA            NA            15\n10                    10            27            NA            NA\n# ℹ 50 more rows\n\n\n.\n\n##Cleaning the Data\nfrogs_orig %&gt;% \n  ##\n  pivot_longer(\n    .,\n    cols = starts_with(\"Temperature\"),\n    cols_vary = \"fastest\",\n    names_to = \"Temp\",\n    values_to = \"Time\"\n  ) %&gt;% \n  ##\n  drop_na() %&gt;% \n  \n  ## \"\\\\d+\" is regex language for 'keep only the digits'all digits'\n  \n  separate_wider_regex(\n    cols = Temp,\n    patterns = c(\"Temperature\", TempFac =\"\\\\d+\"),\n    cols_remove = TRUE\n  ) %&gt;% \n  mutate(\n    TempFac = factor(\n      x = TempFac,\n      levels = c(13,18,25),\n      labels = c(\"13\",\"18\",\"25\")\n    )\n    ) %&gt;% \n    rename(\"Id\" = 'Frogspawn sample id') -&gt; frogs_long\n\nfrogs_long\n\n# A tibble: 60 × 3\n      Id TempFac  Time\n   &lt;dbl&gt; &lt;fct&gt;   &lt;dbl&gt;\n 1     1 13         24\n 2     2 18         21\n 3     3 25         18\n 4     4 13         26\n 5     5 18         22\n 6     6 25         14\n 7     7 13         27\n 8     8 18         22\n 9     9 25         15\n10    10 13         27\n# ℹ 50 more rows\n\n##\nfrogs_long %&gt;% count(TempFac)\n\n# A tibble: 3 × 2\n  TempFac     n\n  &lt;fct&gt;   &lt;int&gt;\n1 13         20\n2 18         20\n3 25         20\n\n\n.\n\n\n\n.\n\n##plotting histograms\n\nfrogs_long %&gt;% \n  gf_histogram( ~ Time,\n              fill = ~TempFac,\n              alpha = 0.5) %&gt;% \n  gf_vline(xintercept = ~mean(Time)) %&gt;% \n  gf_labs(\n    title = \"Histograms of Hatching Time Distributions vs Temperature\",\n    x = \"Hatching Time\", y = \"Count\"\n  ) %&gt;%\n  gf_text(7 ~ (mean(Time) + 2),\n    label = \"Overall Mean\"\n  ) %&gt;%\n  gf_refine(guides(fill = guide_legend(title = \"Temperature level (°C)\")))\n\n\n\n\n\n\n\n## Its clear to see that eggs hatch faster if the temperature is higher.\n\n.\n\n## plotting boxplots\ngf_boxplot(\n  data = frogs_long,\n  Time ~ TempFac,\n  fill = ~TempFac,\n  alpha = 0.5\n) %&gt;%\n  gf_vline(xintercept = ~ mean(Time)) %&gt;%\n  gf_labs(\n    title = \"Boxplots of Hatching Time Distributions vs Temperature\",\n    x = \"Temperature\", y = \"Hatching Time\",\n    caption = \"Using ggprism\"\n  ) %&gt;%\n  gf_refine(\n    scale_x_discrete(guide = \"prism_bracket\"),\n    guides(fill = guide_legend(title = \"Temperature level (°C)\"))\n  )\n\nWarning: The S3 guide system was deprecated in ggplot2 3.5.0.\nℹ It has been replaced by a ggproto system that can be extended.\n\n\n\n\n\n\n\n\n## there is very little overlap - both the boxplots and the histograms indicate that temperature has a significant effect on hatching time.\n\n.\n\n\n\n.\n\nfrogs_anova &lt;- aov(Time ~ TempFac, data = frogs_long)\n##\nsupernova::pairwise(frogs_anova,\n  correction = \"Bonferroni\", # Try \"Tukey\"\n  alpha = 0.05, # 95% CI calculation\n  var_equal = TRUE, # We'll see\n  plot = TRUE\n)\n\n\n\n\n\n\n\n\n\n\n\n── Pairwise t-tests with Bonferroni correction ─────────────────────────────────\n\n\nModel: Time ~ TempFac\n\n\nTempFac\n\n\nLevels: 3\n\n\nFamily-wise error-rate: 0.049\n\n\n\n  group_1 group_2    diff pooled_se       t    df   lower  upper p_adj\n  &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 18      13       -5.300     0.257 -20.608    57  -5.861 -4.739 .0000\n2 25      13      -10.100     0.257 -39.272    57 -10.661 -9.539 .0000\n3 25      18       -4.800     0.257 -18.664    57  -5.361 -4.239 .0000\n\n## What is ANOVA doing? It's analyzing the variance...\n## Total variance vs var1, var2, var3 --&gt; the difference is so huge.\n\n."
  },
  {
    "objectID": "posts/Day 7/index.html#introduction",
    "href": "posts/Day 7/index.html#introduction",
    "title": "Day 7: Comparing Multiple Means with ANOVA",
    "section": "",
    "text": ".\n\n\n\n#| label: setup}\n\nlibrary(tidyverse) # Tidy data processing\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggformula) # Formula based plots\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(mosaic) # Data inspection and Statistical Inference\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(broom) # Tidy outputs from Statistical Analyses\nlibrary(infer) # Statistical Inference, Permutation/Bootstrap\n\n\nAttaching package: 'infer'\n\nThe following objects are masked from 'package:mosaic':\n\n    prop_test, t_test\n\nlibrary(patchwork) # Arranging Plots\nlibrary(ggprism) # Interesting Categorical Axes\nlibrary(supernova) # Beginner-Friendly ANOVA Tables\n\n\nAttaching package: 'supernova'\n\nThe following object is masked from 'package:scales':\n\n    number\n\n\n.\n."
  },
  {
    "objectID": "posts/Day 7/index.html#reading-and-examining-the-data",
    "href": "posts/Day 7/index.html#reading-and-examining-the-data",
    "title": "Day 7: Comparing Multiple Means with ANOVA",
    "section": "",
    "text": "## Calling Data\nfrogs_orig &lt;- read_delim(file =\"../../Data/frogs.csv\", delim = \",\")\n\nRows: 60 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (4): Frogspawn sample id, Temperature13, Temperature18, Temperature25\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nfrogs_orig\n\n# A tibble: 60 × 4\n   `Frogspawn sample id` Temperature13 Temperature18 Temperature25\n                   &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n 1                     1            24            NA            NA\n 2                     2            NA            21            NA\n 3                     3            NA            NA            18\n 4                     4            26            NA            NA\n 5                     5            NA            22            NA\n 6                     6            NA            NA            14\n 7                     7            27            NA            NA\n 8                     8            NA            22            NA\n 9                     9            NA            NA            15\n10                    10            27            NA            NA\n# ℹ 50 more rows\n\n\n.\n\n##Cleaning the Data\nfrogs_orig %&gt;% \n  ##\n  pivot_longer(\n    .,\n    cols = starts_with(\"Temperature\"),\n    cols_vary = \"fastest\",\n    names_to = \"Temp\",\n    values_to = \"Time\"\n  ) %&gt;% \n  ##\n  drop_na() %&gt;% \n  \n  ## \"\\\\d+\" is regex language for 'keep only the digits'all digits'\n  \n  separate_wider_regex(\n    cols = Temp,\n    patterns = c(\"Temperature\", TempFac =\"\\\\d+\"),\n    cols_remove = TRUE\n  ) %&gt;% \n  mutate(\n    TempFac = factor(\n      x = TempFac,\n      levels = c(13,18,25),\n      labels = c(\"13\",\"18\",\"25\")\n    )\n    ) %&gt;% \n    rename(\"Id\" = 'Frogspawn sample id') -&gt; frogs_long\n\nfrogs_long\n\n# A tibble: 60 × 3\n      Id TempFac  Time\n   &lt;dbl&gt; &lt;fct&gt;   &lt;dbl&gt;\n 1     1 13         24\n 2     2 18         21\n 3     3 25         18\n 4     4 13         26\n 5     5 18         22\n 6     6 25         14\n 7     7 13         27\n 8     8 18         22\n 9     9 25         15\n10    10 13         27\n# ℹ 50 more rows\n\n##\nfrogs_long %&gt;% count(TempFac)\n\n# A tibble: 3 × 2\n  TempFac     n\n  &lt;fct&gt;   &lt;int&gt;\n1 13         20\n2 18         20\n3 25         20\n\n\n."
  },
  {
    "objectID": "posts/Day 7/index.html#plotting-data",
    "href": "posts/Day 7/index.html#plotting-data",
    "title": "Day 7: Comparing Multiple Means with ANOVA",
    "section": "",
    "text": ".\n\n##plotting histograms\n\nfrogs_long %&gt;% \n  gf_histogram( ~ Time,\n              fill = ~TempFac,\n              alpha = 0.5) %&gt;% \n  gf_vline(xintercept = ~mean(Time)) %&gt;% \n  gf_labs(\n    title = \"Histograms of Hatching Time Distributions vs Temperature\",\n    x = \"Hatching Time\", y = \"Count\"\n  ) %&gt;%\n  gf_text(7 ~ (mean(Time) + 2),\n    label = \"Overall Mean\"\n  ) %&gt;%\n  gf_refine(guides(fill = guide_legend(title = \"Temperature level (°C)\")))\n\n\n\n\n\n\n\n## Its clear to see that eggs hatch faster if the temperature is higher.\n\n.\n\n## plotting boxplots\ngf_boxplot(\n  data = frogs_long,\n  Time ~ TempFac,\n  fill = ~TempFac,\n  alpha = 0.5\n) %&gt;%\n  gf_vline(xintercept = ~ mean(Time)) %&gt;%\n  gf_labs(\n    title = \"Boxplots of Hatching Time Distributions vs Temperature\",\n    x = \"Temperature\", y = \"Hatching Time\",\n    caption = \"Using ggprism\"\n  ) %&gt;%\n  gf_refine(\n    scale_x_discrete(guide = \"prism_bracket\"),\n    guides(fill = guide_legend(title = \"Temperature level (°C)\"))\n  )\n\nWarning: The S3 guide system was deprecated in ggplot2 3.5.0.\nℹ It has been replaced by a ggproto system that can be extended.\n\n\n\n\n\n\n\n\n## there is very little overlap - both the boxplots and the histograms indicate that temperature has a significant effect on hatching time.\n\n."
  },
  {
    "objectID": "posts/Day 7/index.html#workflow-anova",
    "href": "posts/Day 7/index.html#workflow-anova",
    "title": "Day 7: Comparing Multiple Means with ANOVA",
    "section": "",
    "text": ".\n\nfrogs_anova &lt;- aov(Time ~ TempFac, data = frogs_long)\n##\nsupernova::pairwise(frogs_anova,\n  correction = \"Bonferroni\", # Try \"Tukey\"\n  alpha = 0.05, # 95% CI calculation\n  var_equal = TRUE, # We'll see\n  plot = TRUE\n)\n\n\n\n\n\n\n\n\n\n\n\n── Pairwise t-tests with Bonferroni correction ─────────────────────────────────\n\n\nModel: Time ~ TempFac\n\n\nTempFac\n\n\nLevels: 3\n\n\nFamily-wise error-rate: 0.049\n\n\n\n  group_1 group_2    diff pooled_se       t    df   lower  upper p_adj\n  &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 18      13       -5.300     0.257 -20.608    57  -5.861 -4.739 .0000\n2 25      13      -10.100     0.257 -39.272    57 -10.661 -9.539 .0000\n3 25      18       -4.800     0.257 -18.664    57  -5.361 -4.239 .0000\n\n## What is ANOVA doing? It's analyzing the variance...\n## Total variance vs var1, var2, var3 --&gt; the difference is so huge.\n\n."
  },
  {
    "objectID": "posts/Day 4/index.html",
    "href": "posts/Day 4/index.html",
    "title": "Day 4: Quantities",
    "section": "",
    "text": "gf_histogram()\n\nbins\n\ngf_facet_wrap()\n\nscales\nnrow\n\ngf_themes()\nfavestats()\ndrop_na()\ncrosstable()\ncrosstable::as_flextable()\narrange(desc()) or arrange(asec())\nfilter( df %in% c())\nslice_max()\n\norder_by\n\nleft_join()\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(crosstable)\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\n\n.\n."
  },
  {
    "objectID": "posts/Day 4/index.html#setting-up",
    "href": "posts/Day 4/index.html#setting-up",
    "title": "Day 4: Quantities",
    "section": "",
    "text": "gf_histogram()\n\nbins\n\ngf_facet_wrap()\n\nscales\nnrow\n\ngf_themes()\nfavestats()\ndrop_na()\ncrosstable()\ncrosstable::as_flextable()\narrange(desc()) or arrange(asec())\nfilter( df %in% c())\nslice_max()\n\norder_by\n\nleft_join()\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(crosstable)\n\n\nAttaching package: 'crosstable'\n\nThe following object is masked from 'package:purrr':\n\n    compact\n\n\n.\n."
  },
  {
    "objectID": "posts/Day 4/index.html#looking-dataset-diamonds",
    "href": "posts/Day 4/index.html#looking-dataset-diamonds",
    "title": "Day 4: Quantities",
    "section": "Looking Dataset “diamonds”:",
    "text": "Looking Dataset “diamonds”:\n.\n\nNotes:\n\nbins = the number of classes\n\nthe y-axis changes when you change the bins as more the number of class groups, less the number of units within that group &gt; count scale changes\nif the number of bins = the number of rows, it would result in a line graph with the area shaded\n\nalpha = opacity, valuable for overlapping values\ngf_facet_wrap = splits the levels of a variable into their respective graphs\nnrow = changes the scale on the y axis\nfree_y = changes the scales on each graph on gf_facet_wrap\n\n\n.\n\ndiamonds\n\n# A tibble: 53,940 × 10\n   carat cut       color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# ℹ 53,930 more rows\n\n\n.\n\ndiamonds %&gt;% glimpse()\n\nRows: 53,940\nColumns: 10\n$ carat   &lt;dbl&gt; 0.23, 0.21, 0.23, 0.29, 0.31, 0.24, 0.24, 0.26, 0.22, 0.23, 0.…\n$ cut     &lt;ord&gt; Ideal, Premium, Good, Premium, Good, Very Good, Very Good, Ver…\n$ color   &lt;ord&gt; E, E, E, I, J, J, I, H, E, H, J, J, F, J, E, E, I, J, J, J, I,…\n$ clarity &lt;ord&gt; SI2, SI1, VS1, VS2, SI2, VVS2, VVS1, SI1, VS2, VS1, SI1, VS1, …\n$ depth   &lt;dbl&gt; 61.5, 59.8, 56.9, 62.4, 63.3, 62.8, 62.3, 61.9, 65.1, 59.4, 64…\n$ table   &lt;dbl&gt; 55, 61, 65, 58, 58, 57, 57, 55, 61, 61, 55, 56, 61, 54, 62, 58…\n$ price   &lt;int&gt; 326, 326, 327, 334, 335, 336, 336, 337, 337, 338, 339, 340, 34…\n$ x       &lt;dbl&gt; 3.95, 3.89, 4.05, 4.20, 4.34, 3.94, 3.95, 4.07, 3.87, 4.00, 4.…\n$ y       &lt;dbl&gt; 3.98, 3.84, 4.07, 4.23, 4.35, 3.96, 3.98, 4.11, 3.78, 4.05, 4.…\n$ z       &lt;dbl&gt; 2.43, 2.31, 2.31, 2.63, 2.75, 2.48, 2.47, 2.53, 2.49, 2.39, 2.…\n\n\n.\n\ndiamonds %&gt;% inspect()\n\n\ncategorical variables:  \n     name   class levels     n missing\n1     cut ordered      5 53940       0\n2   color ordered      7 53940       0\n3 clarity ordered      8 53940       0\n                                   distribution\n1 Ideal (40%), Premium (25.6%) ...             \n2 G (20.9%), E (18.2%), F (17.7%) ...          \n3 SI1 (24.2%), VS2 (22.7%), SI2 (17%) ...      \n\nquantitative variables:  \n   name   class   min     Q1  median      Q3      max         mean           sd\n1 carat numeric   0.2   0.40    0.70    1.04     5.01    0.7979397    0.4740112\n2 depth numeric  43.0  61.00   61.80   62.50    79.00   61.7494049    1.4326213\n3 table numeric  43.0  56.00   57.00   59.00    95.00   57.4571839    2.2344906\n4 price integer 326.0 950.00 2401.00 5324.25 18823.00 3932.7997219 3989.4397381\n5     x numeric   0.0   4.71    5.70    6.54    10.74    5.7311572    1.1217607\n6     y numeric   0.0   4.72    5.71    6.54    58.90    5.7345260    1.1421347\n7     z numeric   0.0   2.91    3.53    4.04    31.80    3.5387338    0.7056988\n      n missing\n1 53940       0\n2 53940       0\n3 53940       0\n4 53940       0\n5 53940       0\n6 53940       0\n7 53940       0\n\n\n.\n\ndiamonds %&gt;% skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n53940\n\n\nNumber of columns\n10\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\ncut\n0\n1\nTRUE\n5\nIde: 21551, Pre: 13791, Ver: 12082, Goo: 4906\n\n\ncolor\n0\n1\nTRUE\n7\nG: 11292, E: 9797, F: 9542, H: 8304\n\n\nclarity\n0\n1\nTRUE\n8\nSI1: 13065, VS2: 12258, SI2: 9194, VS1: 8171\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ncarat\n0\n1\n0.80\n0.47\n0.2\n0.40\n0.70\n1.04\n5.01\n▇▂▁▁▁\n\n\ndepth\n0\n1\n61.75\n1.43\n43.0\n61.00\n61.80\n62.50\n79.00\n▁▁▇▁▁\n\n\ntable\n0\n1\n57.46\n2.23\n43.0\n56.00\n57.00\n59.00\n95.00\n▁▇▁▁▁\n\n\nprice\n0\n1\n3932.80\n3989.44\n326.0\n950.00\n2401.00\n5324.25\n18823.00\n▇▂▁▁▁\n\n\nx\n0\n1\n5.73\n1.12\n0.0\n4.71\n5.70\n6.54\n10.74\n▁▁▇▃▁\n\n\ny\n0\n1\n5.73\n1.14\n0.0\n4.72\n5.71\n6.54\n58.90\n▇▁▁▁▁\n\n\nz\n0\n1\n3.54\n0.71\n0.0\n2.91\n3.53\n4.04\n31.80\n▇▁▁▁▁\n\n\n\n\n\n.\n."
  },
  {
    "objectID": "posts/Day 4/index.html#munging-data",
    "href": "posts/Day 4/index.html#munging-data",
    "title": "Day 4: Quantities",
    "section": "Munging Data:",
    "text": "Munging Data:\nThere’s nothing to be munged!\n.\n."
  },
  {
    "objectID": "posts/Day 4/index.html#q1-price-distribution",
    "href": "posts/Day 4/index.html#q1-price-distribution",
    "title": "Day 4: Quantities",
    "section": "Q1: Price Distribution",
    "text": "Q1: Price Distribution\n.\n\n## Plotting the distribution of Diamond Prices\ndiamonds %&gt;% \n  gf_histogram(~price) %&gt;%\n  gf_labs(\n    title = \"Plot 1A: Diamond Prices\",\n    caption = \"bins=default=25\"\n  )\n\n\n\n\n\n\n\n\n.\n\n##What happens when you change the bins?\ndiamonds %&gt;% \n  gf_histogram(~price,\n               bins =100) %&gt;%\n  gf_labs(\n    title = \"Plot 1B: Diamond Prices\",\n    caption = \"bins=100\"\n  )\n\n\n\n\n\n\n\n\n.\n."
  },
  {
    "objectID": "posts/Day 4/index.html#q2-carat-distribution",
    "href": "posts/Day 4/index.html#q2-carat-distribution",
    "title": "Day 4: Quantities",
    "section": "Q2: Carat Distribution",
    "text": "Q2: Carat Distribution\n.\n\n## Plotting the distribution of diamonds with different Carats\ndiamonds %&gt;% \n  gf_histogram(~carat) %&gt;%\n  gf_labs(\n    title = \"Plot 2A: Diamond Carats\",\n    caption = \"bins=default=25\"\n  )\n\n\n\n\n\n\n\n\n\n## Putting bins at 100\ndiamonds %&gt;% \n  gf_histogram(~carat,\n               bins = 100) %&gt;%\n  gf_labs(\n    title = \"Plot 2B: Diamond Carats\",\n    caption = \"bins=100\"\n  )\n\n\n\n\n\n\n\n\n\n## Putting bins at 200\ndiamonds %&gt;% \n  gf_histogram(~carat,\n               bins = 200) %&gt;%\n  gf_labs(\n    title = \"Plot 2C: Diamond Carats\",\n    caption = \"bins=200\"\n  )\n\n\n\n\n\n\n\n\n.\n\n## What about when bins are 2000?\ndiamonds %&gt;% \n  gf_plot(~carat,\n               bins = 2000) %&gt;%\n  gf_labs(\n    title = \"Plot 2D: Diamond Carats\",\n    caption = \"bins=2000\"\n  )\n\n\n\n\n\n\n\n\n.\n\nObservations:\n\nSome towers are really high, and some are very low: this suggests that there are certain values of diamonds that are more standard than others, i.e, one is more likely to find 1, 1.5 and 2 carat diamonds than perhaps a 1.8 or 1.9 carat diamond."
  },
  {
    "objectID": "posts/Day 4/index.html#q3-price-distribution-based-on-cut-clarity-color",
    "href": "posts/Day 4/index.html#q3-price-distribution-based-on-cut-clarity-color",
    "title": "Day 4: Quantities",
    "section": "Q3: Price Distribution based on Cut, Clarity, Color",
    "text": "Q3: Price Distribution based on Cut, Clarity, Color\n\ncan you stack and dodge in histograms?\n\n\ndiamonds %&gt;% \n  gf_histogram( ~price,\n               fill = ~cut,\n               color = \"violet\",\n               alpha = 0.8) %&gt;%\n  gf_labs(\n    title=\"Plot 3A: Price distribution based on Cut\",\n    caption=\"bins=default=25\"\n  )\n\n\n\n\n\n\n\n\n\ndiamonds %&gt;% \n  gf_histogram( ~price,\n               fill = ~cut,\n               position = \"dodge\",\n               color = \"violet\",\n               alpha = 0.8) %&gt;%\n  gf_labs(\n    title=\"Plot 3B: Price distribution based on Cut\",\n    caption=\"bins = 25, position = dodge\"\n  )\n\n\n\n\n\n\n\n\n\ndiamonds %&gt;% \n  gf_histogram( ~price,\n               fill = ~cut,\n               position = \"fill\",\n               color = \"violet\",\n               alpha = 0.8) %&gt;%\n  gf_labs(\n    title=\"Plot 3C: Price distribution based on Cut\",\n    caption=\"bins = 25, position = fill\"\n  )\n\n\n\n\n\n\n\n\n\nPosition ‘dodge’ and ‘stacked’ act as default for gf_facet_wrap. Fill doesn’t make any sense to do as all coloumns would be 1 and filled.\n\n\ndiamonds %&gt;% \n  gf_histogram( ~price,\n               fill = ~cut,\n               color = \"violet\",\n               alpha = 0.8) %&gt;%\n  gf_facet_wrap(~cut) %&gt;% \n  gf_labs(\n    title=\"Plot 3B: Prices by Filled and Facetted by Cut\",\n    caption=\"bins = 25\"\n  )\n\n\n\n\n\n\n\n\n\ndiamonds %&gt;%\n  gf_histogram(~price, fill = ~cut, color = \"violet\", alpha = 0.3) %&gt;%\n  gf_facet_wrap(~cut, scales = \"free_y\", nrow = 2) %&gt;%\n  gf_labs(\n    title = \"Plot 3D: Prices Filled and Facetted by Cut\",\n    subtitle = \"Free y-scale, nrow = 2\",\n    caption = \"ggformula\"\n  ) %&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\n\ndiamonds %&gt;%\n  gf_histogram(~price, fill = ~cut, color = \"violet\", alpha = 0.3) %&gt;%\n  gf_facet_wrap(~cut, scales = \"free_y\", nrow = 5) %&gt;%\n  gf_labs(\n    title = \"Plot 3D: Prices Filled and Facetted by Cut\",\n    subtitle = \"Free y-scale, nrow = 5\",\n    caption = \"ggformula\"\n  ) %&gt;%\n  gf_theme(theme(\n    axis.text.x =\n      element_text(\n        angle = 45,\n        hjust = 1\n      )\n  ))\n\n\n\n\n\n\n\n\n.\n."
  },
  {
    "objectID": "posts/Day 4/index.html#looking-at-data-sets-race-and-rank",
    "href": "posts/Day 4/index.html#looking-at-data-sets-race-and-rank",
    "title": "Day 4: Quantities",
    "section": "Looking at Data sets ‘race’ and ‘rank’:",
    "text": "Looking at Data sets ‘race’ and ‘rank’:\n.\n\nNotes:\n\nfavestats = singles out specified row and gives its stats\ncrosstables = tabling more than two variables against each other\ndrop_na() = removes all missing variables\n\n\n.\n\n## Reading race data frame\n##\nrace_df &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-26/race.csv\")\n\nRows: 1207 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (5): event, race, city, country, participation\ndbl  (6): race_year_id, distance, elevation_gain, elevation_loss, aid_statio...\ndate (1): date\ntime (1): start_time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n##\n##reading rank data frame\n##\nrank_df &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-26/ultra_rankings.csv\")\n\nRows: 137803 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): runner, time, gender, nationality\ndbl (4): race_year_id, rank, age, time_in_seconds\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nrace_df %&gt;% glimpse()\n\nRows: 1,207\nColumns: 13\n$ race_year_id   &lt;dbl&gt; 68140, 72496, 69855, 67856, 70469, 66887, 67851, 68241,…\n$ event          &lt;chr&gt; \"Peak District Ultras\", \"UTMB®\", \"Grand Raid des Pyréné…\n$ race           &lt;chr&gt; \"Millstone 100\", \"UTMB®\", \"Ultra Tour 160\", \"PERSENK UL…\n$ city           &lt;chr&gt; \"Castleton\", \"Chamonix\", \"vielle-Aure\", \"Asenovgrad\", \"…\n$ country        &lt;chr&gt; \"United Kingdom\", \"France\", \"France\", \"Bulgaria\", \"Turk…\n$ date           &lt;date&gt; 2021-09-03, 2021-08-27, 2021-08-20, 2021-08-20, 2021-0…\n$ start_time     &lt;time&gt; 19:00:00, 17:00:00, 05:00:00, 18:00:00, 18:00:00, 17:0…\n$ participation  &lt;chr&gt; \"solo\", \"Solo\", \"solo\", \"solo\", \"solo\", \"solo\", \"solo\",…\n$ distance       &lt;dbl&gt; 166.9, 170.7, 167.0, 164.0, 159.9, 159.9, 163.8, 163.9,…\n$ elevation_gain &lt;dbl&gt; 4520, 9930, 9980, 7490, 100, 9850, 5460, 4630, 6410, 31…\n$ elevation_loss &lt;dbl&gt; -4520, -9930, -9980, -7500, -100, -9850, -5460, -4660, …\n$ aid_stations   &lt;dbl&gt; 10, 11, 13, 13, 12, 15, 5, 8, 13, 23, 13, 5, 12, 15, 0,…\n$ participants   &lt;dbl&gt; 150, 2300, 600, 150, 0, 300, 0, 200, 120, 100, 300, 50,…\n\n\n\nrace_df %&gt;%skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n1207\n\n\nNumber of columns\n13\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nDate\n1\n\n\ndifftime\n1\n\n\nnumeric\n6\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nevent\n0\n1.00\n4\n57\n0\n435\n0\n\n\nrace\n0\n1.00\n3\n63\n0\n371\n0\n\n\ncity\n172\n0.86\n2\n30\n0\n308\n0\n\n\ncountry\n4\n1.00\n4\n17\n0\n60\n0\n\n\nparticipation\n0\n1.00\n4\n5\n0\n4\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndate\n0\n1\n2012-01-14\n2021-09-03\n2017-09-30\n711\n\n\n\nVariable type: difftime\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nstart_time\n0\n1\n0 secs\n82800 secs\n05:00:00\n39\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrace_year_id\n0\n1\n27889.65\n20689.90\n2320\n9813.5\n23565.0\n42686.00\n72496.0\n▇▃▃▂▂\n\n\ndistance\n0\n1\n152.62\n39.88\n0\n160.1\n161.5\n165.15\n179.1\n▁▁▁▁▇\n\n\nelevation_gain\n0\n1\n5294.79\n2872.29\n0\n3210.0\n5420.0\n7145.00\n14430.0\n▅▇▇▂▁\n\n\nelevation_loss\n0\n1\n-5317.01\n2899.12\n-14440\n-7206.5\n-5420.0\n-3220.00\n0.0\n▁▂▇▇▅\n\n\naid_stations\n0\n1\n8.63\n7.63\n0\n0.0\n9.0\n14.00\n56.0\n▇▆▁▁▁\n\n\nparticipants\n0\n1\n120.49\n281.83\n0\n0.0\n21.0\n150.00\n2900.0\n▇▁▁▁▁\n\n\n\n\n\n\nrank_df %&gt;%glimpse()\n\nRows: 137,803\nColumns: 8\n$ race_year_id    &lt;dbl&gt; 68140, 68140, 68140, 68140, 68140, 68140, 68140, 68140…\n$ rank            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, NA, NA, NA,…\n$ runner          &lt;chr&gt; \"VERHEUL Jasper\", \"MOULDING JON\", \"RICHARDSON Phill\", …\n$ time            &lt;chr&gt; \"26H 35M 25S\", \"27H 0M 29S\", \"28H 49M 7S\", \"30H 53M 37…\n$ age             &lt;dbl&gt; 30, 43, 38, 55, 48, 31, 55, 40, 47, 29, 48, 47, 52, 49…\n$ gender          &lt;chr&gt; \"M\", \"M\", \"M\", \"W\", \"W\", \"M\", \"W\", \"W\", \"M\", \"M\", \"M\",…\n$ nationality     &lt;chr&gt; \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\"…\n$ time_in_seconds &lt;dbl&gt; 95725, 97229, 103747, 111217, 117981, 118000, 120601, …\n\n\n\nrank_df %&gt;%skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n137803\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nrunner\n0\n1.00\n3\n52\n0\n73629\n0\n\n\ntime\n17791\n0.87\n8\n11\n0\n72840\n0\n\n\ngender\n30\n1.00\n1\n1\n0\n2\n0\n\n\nnationality\n0\n1.00\n3\n3\n0\n133\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrace_year_id\n0\n1.00\n26678.70\n20156.18\n2320\n8670\n21795\n40621\n72496\n▇▃▃▂▂\n\n\nrank\n17791\n0.87\n253.56\n390.80\n1\n31\n87\n235\n1962\n▇▁▁▁▁\n\n\nage\n0\n1.00\n46.25\n10.11\n0\n40\n46\n53\n133\n▁▇▂▁▁\n\n\ntime_in_seconds\n17791\n0.87\n122358.26\n37234.38\n3600\n96566\n114167\n148020\n296806\n▁▇▆▁▁\n\n\n\n\n\n.\n\nUsing mosaic::favestats:\n\nrace_df %&gt;%\n  favstats(~distance, data = .)\n\n min    Q1 median     Q3   max     mean       sd    n missing\n   0 160.1  161.5 165.15 179.1 152.6187 39.87864 1207       0\n\n\n\nrace_df %&gt;%\n  favstats(~participants, data = .)\n\n min Q1 median  Q3  max     mean       sd    n missing\n   0  0     21 150 2900 120.4872 281.8337 1207       0\n\n\n\n##\nrank_df %&gt;%\n  drop_na() %&gt;%\n  favstats(time_in_seconds ~ gender, data = .)\n\n  gender  min      Q1 median       Q3    max     mean       sd      n missing\n1      M 3600 96536.5 115845 149761.5 288000 123271.1 37615.42 101643       0\n2      W 9191 96695.0 107062 131464.0 296806 117296.5 34604.26  18341       0\n\n\n.\n.\n\n\nData Dictionary:"
  },
  {
    "objectID": "posts/Day 4/index.html#coming-up-with-questions",
    "href": "posts/Day 4/index.html#coming-up-with-questions",
    "title": "Day 4: Quantities",
    "section": "Coming up with Questions:",
    "text": "Coming up with Questions:\n\nDo gender and age affect time in seconds"
  },
  {
    "objectID": "posts/Day 4/index.html#q1",
    "href": "posts/Day 4/index.html#q1",
    "title": "Day 4: Quantities",
    "section": "Q1:",
    "text": "Q1:"
  },
  {
    "objectID": "posts/Day 4/index.html#q2",
    "href": "posts/Day 4/index.html#q2",
    "title": "Day 4: Quantities",
    "section": "Q2:",
    "text": "Q2:"
  },
  {
    "objectID": "posts/Day 2/index.html",
    "href": "posts/Day 2/index.html",
    "title": "Day 2: Summaries",
    "section": "",
    "text": "How do we make data sets more readable? How can we decide how to group variables and compare them against each other in terms of what we are using the data for? This is my journey of exploring these questions with the help of Data Summaries.\n\n\n\nInstall and call packages to the document\nSelect and call chosen data set\nExamining Data: Glimpse, Inspect, Skim and their different syntax\nData Munging: mutate(), as_factor(), group_by() and summarise()\nExploring babynames data set\nExploring Startrek data set\n\n\n.\n.\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggformula)\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(knitr)\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nlibrary(babynames)\n\n.\n.\n\n\n\nInstalling packages makes them available to all documents created in the future. {syntax: install.packages(““)}\nIn each document however, one must call on the packages using {library()} to “activate” them.\nDon’t forget to add { #| label: setup } in the first code chunk when calling the packages\nHave only one quarto document open in one window, as R treats a session as a single data pool and can pull libraries across documents (which could complicate things later.\n\n\n.\n."
  },
  {
    "objectID": "posts/Day 2/index.html#introduction",
    "href": "posts/Day 2/index.html#introduction",
    "title": "Day 2: Summaries",
    "section": "",
    "text": "How do we make data sets more readable? How can we decide how to group variables and compare them against each other in terms of what we are using the data for? This is my journey of exploring these questions with the help of Data Summaries.\n\n\n\nInstall and call packages to the document\nSelect and call chosen data set\nExamining Data: Glimpse, Inspect, Skim and their different syntax\nData Munging: mutate(), as_factor(), group_by() and summarise()\nExploring babynames data set\nExploring Startrek data set\n\n\n.\n.\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggformula)\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(knitr)\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nlibrary(babynames)\n\n.\n.\n\n\n\nInstalling packages makes them available to all documents created in the future. {syntax: install.packages(““)}\nIn each document however, one must call on the packages using {library()} to “activate” them.\nDon’t forget to add { #| label: setup } in the first code chunk when calling the packages\nHave only one quarto document open in one window, as R treats a session as a single data pool and can pull libraries across documents (which could complicate things later.\n\n\n.\n."
  },
  {
    "objectID": "posts/Day 2/index.html#looking-at-the-mpg-data-set",
    "href": "posts/Day 2/index.html#looking-at-the-mpg-data-set",
    "title": "Day 2: Summaries",
    "section": "Looking at the ‘mpg’ Data Set:",
    "text": "Looking at the ‘mpg’ Data Set:\n\nmpg\n\n# A tibble: 234 × 11\n   manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n   &lt;chr&gt;        &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n 1 audi         a4           1.8  1999     4 auto… f        18    29 p     comp…\n 2 audi         a4           1.8  1999     4 manu… f        21    29 p     comp…\n 3 audi         a4           2    2008     4 manu… f        20    31 p     comp…\n 4 audi         a4           2    2008     4 auto… f        21    30 p     comp…\n 5 audi         a4           2.8  1999     6 auto… f        16    26 p     comp…\n 6 audi         a4           2.8  1999     6 manu… f        18    26 p     comp…\n 7 audi         a4           3.1  2008     6 auto… f        18    27 p     comp…\n 8 audi         a4 quattro   1.8  1999     4 manu… 4        18    26 p     comp…\n 9 audi         a4 quattro   1.8  1999     4 auto… 4        16    25 p     comp…\n10 audi         a4 quattro   2    2008     4 manu… 4        20    28 p     comp…\n# ℹ 224 more rows\n\n\n.\n\nmpg %&gt;%\n  head(10) %&gt;%\n  kbl(\n    # add Human Readable column names\n    col.names = c(\n      \"Manufacturer\", \"Model\", \"Engine\\nDisplacement\",\n      \"Model\\n Year\", \"Cylinders\", \"Transmission\",\n      \"Drivetrain\", \"City\\n Mileage\", \"Highway\\n Mileage\",\n      \"Fuel\", \"Class\\nOf\\nVehicle\"\n    ),\n    caption = \"MPG Dataset\"\n  ) %&gt;%\n  kable_styling(\n    bootstrap_options = c(\n      \"striped\", \"hover\",\n      \"condensed\", \"responsive\"\n    ),\n    full_width = F, position = \"center\"\n  )\n\n\n\nMPG Dataset\n\n\nManufacturer\nModel\nEngine Displacement\nModel Year\nCylinders\nTransmission\nDrivetrain\nCity Mileage\nHighway Mileage\nFuel\nClass Of Vehicle\n\n\n\n\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n\n\naudi\na4\n2.8\n1999\n6\nmanual(m5)\nf\n18\n26\np\ncompact\n\n\naudi\na4\n3.1\n2008\n6\nauto(av)\nf\n18\n27\np\ncompact\n\n\naudi\na4 quattro\n1.8\n1999\n4\nmanual(m5)\n4\n18\n26\np\ncompact\n\n\naudi\na4 quattro\n1.8\n1999\n4\nauto(l5)\n4\n16\n25\np\ncompact\n\n\naudi\na4 quattro\n2.0\n2008\n4\nmanual(m6)\n4\n20\n28\np\ncompact\n\n\n\n\n\n\n\n\n.\n.\n\nNotes\n\nkbl - from the kableExtra package\nmakes the data more human readable\nhead(10) indicates the table will show 10 rows.\n‘\\n’ acts as line break\nStyling (kable_styling):\n\nThe table is styled using kable_styling with several bootstrap_options for appearance:\n\n“striped”: Alternating background colors on rows.\n“hover”: Highlights rows when hovering over them.\n“condensed”: Reduces the row height to make the table more compact.\n“responsive”: Ensures the table adjusts to different screen sizes.\n\nfull_width = F ensures that the table is not stretched to fill the entire width of the page but rather centered, as specified by position = “center”.\n\n\n\n.\n.\n\nUsing Glimpse\n\nglimpse(mpg)\n\nRows: 234\nColumns: 11\n$ manufacturer &lt;chr&gt; \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"…\n$ model        &lt;chr&gt; \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4 quattro\", \"…\n$ displ        &lt;dbl&gt; 1.8, 1.8, 2.0, 2.0, 2.8, 2.8, 3.1, 1.8, 1.8, 2.0, 2.0, 2.…\n$ year         &lt;int&gt; 1999, 1999, 2008, 2008, 1999, 1999, 2008, 1999, 1999, 200…\n$ cyl          &lt;int&gt; 4, 4, 4, 4, 6, 6, 6, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, …\n$ trans        &lt;chr&gt; \"auto(l5)\", \"manual(m5)\", \"manual(m6)\", \"auto(av)\", \"auto…\n$ drv          &lt;chr&gt; \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"4\", \"4\", \"4\", \"4\", \"4…\n$ cty          &lt;int&gt; 18, 21, 20, 21, 16, 18, 18, 18, 16, 20, 19, 15, 17, 17, 1…\n$ hwy          &lt;int&gt; 29, 29, 31, 30, 26, 26, 27, 26, 25, 28, 27, 25, 25, 25, 2…\n$ fl           &lt;chr&gt; \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p…\n$ class        &lt;chr&gt; \"compact\", \"compact\", \"compact\", \"compact\", \"compact\", \"c…\n\n\n\nTesting different syntax:\n\nmpg %&gt;% dplyr::glimpse()\n\nRows: 234\nColumns: 11\n$ manufacturer &lt;chr&gt; \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"…\n$ model        &lt;chr&gt; \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4 quattro\", \"…\n$ displ        &lt;dbl&gt; 1.8, 1.8, 2.0, 2.0, 2.8, 2.8, 3.1, 1.8, 1.8, 2.0, 2.0, 2.…\n$ year         &lt;int&gt; 1999, 1999, 2008, 2008, 1999, 1999, 2008, 1999, 1999, 200…\n$ cyl          &lt;int&gt; 4, 4, 4, 4, 6, 6, 6, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, …\n$ trans        &lt;chr&gt; \"auto(l5)\", \"manual(m5)\", \"manual(m6)\", \"auto(av)\", \"auto…\n$ drv          &lt;chr&gt; \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"4\", \"4\", \"4\", \"4\", \"4…\n$ cty          &lt;int&gt; 18, 21, 20, 21, 16, 18, 18, 18, 16, 20, 19, 15, 17, 17, 1…\n$ hwy          &lt;int&gt; 29, 29, 31, 30, 26, 26, 27, 26, 25, 28, 27, 25, 25, 25, 2…\n$ fl           &lt;chr&gt; \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p…\n$ class        &lt;chr&gt; \"compact\", \"compact\", \"compact\", \"compact\", \"compact\", \"c…\n\n\n.\n\nNotes\n\nsyntax essentially boils down to personal preference and readability of code.\n\n\n.\n\n\n\nUsing Inspect\n\ninspect(mpg)\n\n\ncategorical variables:  \n          name     class levels   n missing\n1 manufacturer character     15 234       0\n2        model character     38 234       0\n3        trans character     10 234       0\n4          drv character      3 234       0\n5           fl character      5 234       0\n6        class character      7 234       0\n                                   distribution\n1 dodge (15.8%), toyota (14.5%) ...            \n2 caravan 2wd (4.7%) ...                       \n3 auto(l4) (35.5%), manual(m5) (24.8%) ...     \n4 f (45.3%), 4 (44%), r (10.7%)                \n5 r (71.8%), p (22.2%), e (3.4%) ...           \n6 suv (26.5%), compact (20.1%) ...             \n\nquantitative variables:  \n   name   class    min     Q1 median     Q3  max        mean       sd   n\n1 displ numeric    1.6    2.4    3.3    4.6    7    3.471795 1.291959 234\n2  year integer 1999.0 1999.0 2003.5 2008.0 2008 2003.500000 4.509646 234\n3   cyl integer    4.0    4.0    6.0    8.0    8    5.888889 1.611534 234\n4   cty integer    9.0   14.0   17.0   19.0   35   16.858974 4.255946 234\n5   hwy integer   12.0   18.0   24.0   27.0   44   23.440171 5.954643 234\n  missing\n1       0\n2       0\n3       0\n4       0\n5       0\n\n\n.\n\n\nUsing Skim\n\nskimr::skim(mpg)\n\n\nData summary\n\n\nName\nmpg\n\n\nNumber of rows\n234\n\n\nNumber of columns\n11\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nmanufacturer\n0\n1\n4\n10\n0\n15\n0\n\n\nmodel\n0\n1\n2\n22\n0\n38\n0\n\n\ntrans\n0\n1\n8\n10\n0\n10\n0\n\n\ndrv\n0\n1\n1\n1\n0\n3\n0\n\n\nfl\n0\n1\n1\n1\n0\n5\n0\n\n\nclass\n0\n1\n3\n10\n0\n7\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ndispl\n0\n1\n3.47\n1.29\n1.6\n2.4\n3.3\n4.6\n7\n▇▆▆▃▁\n\n\nyear\n0\n1\n2003.50\n4.51\n1999.0\n1999.0\n2003.5\n2008.0\n2008\n▇▁▁▁▇\n\n\ncyl\n0\n1\n5.89\n1.61\n4.0\n4.0\n6.0\n8.0\n8\n▇▁▇▁▇\n\n\ncty\n0\n1\n16.86\n4.26\n9.0\n14.0\n17.0\n19.0\n35\n▆▇▃▁▁\n\n\nhwy\n0\n1\n23.44\n5.95\n12.0\n18.0\n24.0\n27.0\n44\n▅▅▇▁▁\n\n\n\n\n\n\nTesting different syntax:\n\nskim(mpg)\n\n\nData summary\n\n\nName\nmpg\n\n\nNumber of rows\n234\n\n\nNumber of columns\n11\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nmanufacturer\n0\n1\n4\n10\n0\n15\n0\n\n\nmodel\n0\n1\n2\n22\n0\n38\n0\n\n\ntrans\n0\n1\n8\n10\n0\n10\n0\n\n\ndrv\n0\n1\n1\n1\n0\n3\n0\n\n\nfl\n0\n1\n1\n1\n0\n5\n0\n\n\nclass\n0\n1\n3\n10\n0\n7\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ndispl\n0\n1\n3.47\n1.29\n1.6\n2.4\n3.3\n4.6\n7\n▇▆▆▃▁\n\n\nyear\n0\n1\n2003.50\n4.51\n1999.0\n1999.0\n2003.5\n2008.0\n2008\n▇▁▁▁▇\n\n\ncyl\n0\n1\n5.89\n1.61\n4.0\n4.0\n6.0\n8.0\n8\n▇▁▇▁▇\n\n\ncty\n0\n1\n16.86\n4.26\n9.0\n14.0\n17.0\n19.0\n35\n▆▇▃▁▁\n\n\nhwy\n0\n1\n23.44\n5.95\n12.0\n18.0\n24.0\n27.0\n44\n▅▅▇▁▁\n\n\n\n\n\n.\n."
  },
  {
    "objectID": "posts/Day 2/index.html#data-munging---mutating-data-according-to-your-intent",
    "href": "posts/Day 2/index.html#data-munging---mutating-data-according-to-your-intent",
    "title": "Day 2: Summaries",
    "section": "Data Munging - Mutating data according to your intent:",
    "text": "Data Munging - Mutating data according to your intent:\n\nmpg_modified &lt;- mpg %&gt;%\n  dplyr::mutate(\n    cyl = as_factor(cyl),\n    fl = as_factor(fl),\n    drv = as_factor(drv),\n    class = as_factor(class),\n    trans = as_factor(trans)\n  )\nglimpse(mpg_modified)\n\nRows: 234\nColumns: 11\n$ manufacturer &lt;chr&gt; \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"…\n$ model        &lt;chr&gt; \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4 quattro\", \"…\n$ displ        &lt;dbl&gt; 1.8, 1.8, 2.0, 2.0, 2.8, 2.8, 3.1, 1.8, 1.8, 2.0, 2.0, 2.…\n$ year         &lt;int&gt; 1999, 1999, 2008, 2008, 1999, 1999, 2008, 1999, 1999, 200…\n$ cyl          &lt;fct&gt; 4, 4, 4, 4, 6, 6, 6, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, …\n$ trans        &lt;fct&gt; auto(l5), manual(m5), manual(m6), auto(av), auto(l5), man…\n$ drv          &lt;fct&gt; f, f, f, f, f, f, f, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, r, …\n$ cty          &lt;int&gt; 18, 21, 20, 21, 16, 18, 18, 18, 16, 20, 19, 15, 17, 17, 1…\n$ hwy          &lt;int&gt; 29, 29, 31, 30, 26, 26, 27, 26, 25, 28, 27, 25, 25, 25, 2…\n$ fl           &lt;fct&gt; p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, r, …\n$ class        &lt;fct&gt; compact, compact, compact, compact, compact, compact, com…\n\n\n\ninspect(mpg_modified)\n\n\ncategorical variables:  \n          name     class levels   n missing\n1 manufacturer character     15 234       0\n2        model character     38 234       0\n3          cyl    factor      4 234       0\n4        trans    factor     10 234       0\n5          drv    factor      3 234       0\n6           fl    factor      5 234       0\n7        class    factor      7 234       0\n                                   distribution\n1 dodge (15.8%), toyota (14.5%) ...            \n2 caravan 2wd (4.7%) ...                       \n3 4 (34.6%), 6 (33.8%), 8 (29.9%) ...          \n4 auto(l4) (35.5%), manual(m5) (24.8%) ...     \n5 f (45.3%), 4 (44%), r (10.7%)                \n6 r (71.8%), p (22.2%), e (3.4%) ...           \n7 suv (26.5%), compact (20.1%) ...             \n\nquantitative variables:  \n   name   class    min     Q1 median     Q3  max        mean       sd   n\n1 displ numeric    1.6    2.4    3.3    4.6    7    3.471795 1.291959 234\n2  year integer 1999.0 1999.0 2003.5 2008.0 2008 2003.500000 4.509646 234\n3   cty integer    9.0   14.0   17.0   19.0   35   16.858974 4.255946 234\n4   hwy integer   12.0   18.0   24.0   27.0   44   23.440171 5.954643 234\n  missing\n1       0\n2       0\n3       0\n4       0\n\n\n.\n\nNotes\n\nWhy make characters into factors? it better organizes the data in hand for plotting.\nSometimes qual data such as year and date are considered as quant data due to their numeric content. These variables can be turned into qual data through munging.\n\n\n.\n\nGrouping by Qualitative Variables\nHighway milage grouped by cylinder type:\n\nmpg_modified %&gt;%\n  group_by(cyl) %&gt;%\n  summarize(average_hwy = mean(hwy), count = n())\n\n# A tibble: 4 × 3\n  cyl   average_hwy count\n  &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt;\n1 4            28.8    81\n2 5            28.8     4\n3 6            22.8    79\n4 8            17.6    70\n\n\nThe average milage of cars based on the cylinder type.\n\nmpg_modified %&gt;%\n  group_by(cyl, fl) %&gt;%\n  summarize(average_hwy = mean(hwy), count = n())\n\n`summarise()` has grouped output by 'cyl'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 13 × 4\n# Groups:   cyl [4]\n   cyl   fl    average_hwy count\n   &lt;fct&gt; &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt;\n 1 4     p            27.8    22\n 2 4     r            28.3    55\n 3 4     d            43       3\n 4 4     c            36       1\n 5 5     r            28.8     4\n 6 6     p            25.3    17\n 7 6     r            22.2    60\n 8 6     e            17       1\n 9 6     d            22       1\n10 8     p            20.8    13\n11 8     r            17.5    49\n12 8     e            12.7     7\n13 8     d            17       1\n\n\n.\nThere should be 20 columns, but only there are only 8 as certain combinations of cars don’t exisit in this data set.\n.\n."
  },
  {
    "objectID": "posts/Day 2/index.html#looking-at-the-babynames-data-set",
    "href": "posts/Day 2/index.html#looking-at-the-babynames-data-set",
    "title": "Day 2: Summaries",
    "section": "Looking at the ‘babynames’ Data Set:",
    "text": "Looking at the ‘babynames’ Data Set:\n\nglimpse(babynames)\n\nRows: 1,924,665\nColumns: 5\n$ year &lt;dbl&gt; 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880,…\n$ sex  &lt;chr&gt; \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", …\n$ name &lt;chr&gt; \"Mary\", \"Anna\", \"Emma\", \"Elizabeth\", \"Minnie\", \"Margaret\", \"Ida\",…\n$ n    &lt;int&gt; 7065, 2604, 2003, 1939, 1746, 1578, 1472, 1414, 1320, 1288, 1258,…\n$ prop &lt;dbl&gt; 0.07238359, 0.02667896, 0.02052149, 0.01986579, 0.01788843, 0.016…\n\n\n\n## readable table for dataset babynames\nbabynames %&gt;%\n  head(20) %&gt;%\n  kbl(\n    \n    col.names = c(\n      \"Year\", \"Sex\", \"Name\",\n      \"Count\", \"Proportion\"\n    ),\n    caption = \"babynames Dataset\"\n  ) %&gt;%\n  kable_styling(\n    bootstrap_options = c(\n      \"striped\", \"hover\",\n      \"condensed\", \"responsive\"\n    ),\n    full_width = F, position = \"center\"\n  )\n\n\n\nbabynames Dataset\n\n\nYear\nSex\nName\nCount\nProportion\n\n\n\n\n1880\nF\nMary\n7065\n0.0723836\n\n\n1880\nF\nAnna\n2604\n0.0266790\n\n\n1880\nF\nEmma\n2003\n0.0205215\n\n\n1880\nF\nElizabeth\n1939\n0.0198658\n\n\n1880\nF\nMinnie\n1746\n0.0178884\n\n\n1880\nF\nMargaret\n1578\n0.0161672\n\n\n1880\nF\nIda\n1472\n0.0150812\n\n\n1880\nF\nAlice\n1414\n0.0144870\n\n\n1880\nF\nBertha\n1320\n0.0135239\n\n\n1880\nF\nSarah\n1288\n0.0131961\n\n\n1880\nF\nAnnie\n1258\n0.0128887\n\n\n1880\nF\nClara\n1226\n0.0125608\n\n\n1880\nF\nElla\n1156\n0.0118437\n\n\n1880\nF\nFlorence\n1063\n0.0108908\n\n\n1880\nF\nCora\n1045\n0.0107064\n\n\n1880\nF\nMartha\n1040\n0.0106552\n\n\n1880\nF\nLaura\n1012\n0.0103683\n\n\n1880\nF\nNellie\n995\n0.0101942\n\n\n1880\nF\nGrace\n982\n0.0100610\n\n\n1880\nF\nCarrie\n949\n0.0097229\n\n\n\n\n\n\n\n\n\ninspect(babynames)\n\n\ncategorical variables:  \n  name     class levels       n missing\n1  sex character      2 1924665       0\n2 name character  97310 1924665       0\n                                   distribution\n1 F (59.1%), M (40.9%)                         \n2 Francis (0%), James (0%) ...                 \n\nquantitative variables:  \n  name   class      min        Q1    median        Q3          max         mean\n1 year numeric 1.88e+03 1.951e+03 1.985e+03 2.003e+03 2.017000e+03 1.974851e+03\n2    n integer 5.00e+00 7.000e+00 1.200e+01 3.200e+01 9.968600e+04 1.808733e+02\n3 prop numeric 2.26e-06 3.870e-06 7.300e-06 2.288e-05 8.154561e-02 1.362963e-04\n            sd       n missing\n1 3.402948e+01 1924665       0\n2 1.533337e+03 1924665       0\n3 1.151693e-03 1924665       0\n\n\n\n## transforming year from a quant variable to a qual variable\nbn_modone &lt;- babynames %&gt;% \n  mutate(\n    year = as_factor(year),\n    name = as_factor(name)\n  )\n\n\n## grouping by sex to see how many names fall under each category totally (playing around with androgenous names)\n\nbn_modtwo &lt;- bn_modone %&gt;%\n  group_by(sex) %&gt;% \n  summarise(n_names = count(sex), Krishna = count(name == \"Krishna\"), Sam = count(name == \"Sam\"),Samuel = count(name == \"Samuel\"), Samantha = count(name == \"Samantha\"), Alex = count(name == \"Alex\"), Alexander = count(name == \"Alexander\"), Alexis = count(name == \"Alexis\"), Kai = count(name == \"Kai\"), Liza = count(name == \"Liza\"), Keethi_Keerti_kirthi_kirti = count(name == \"Keerthi\" | name == \"Kirti\"|name == \"Keerti\"|name == \"Kirthi\"), Manal = count(name == \"Manal\"))\n\nglimpse(bn_modtwo)\n\nRows: 2\nColumns: 13\n$ sex                        &lt;chr&gt; \"F\", \"M\"\n$ n_names                    &lt;int&gt; 1138293, 786372\n$ Krishna                    &lt;int&gt; 58, 56\n$ Sam                        &lt;int&gt; 115, 138\n$ Samuel                     &lt;int&gt; 113, 138\n$ Samantha                   &lt;int&gt; 138, 50\n$ Alex                       &lt;int&gt; 99, 138\n$ Alexander                  &lt;int&gt; 88, 138\n$ Alexis                     &lt;int&gt; 78, 110\n$ Kai                        &lt;int&gt; 62, 72\n$ Liza                       &lt;int&gt; 138, 2\n$ Keethi_Keerti_kirthi_kirti &lt;int&gt; 35, 0\n$ Manal                      &lt;int&gt; 50, 0\n\n\n\n## trying to understand what exactly count(sex) means, as there are 'M' and 'F' both...\nbn_modthree &lt;- bn_modone %&gt;%\n  group_by(year) %&gt;% \n  summarise(n_names = count(sex))\n\nglimpse(bn_modthree)\n\nRows: 138\nColumns: 2\n$ year    &lt;fct&gt; 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 18…\n$ n_names &lt;int&gt; 942, 938, 1028, 1054, 1172, 1197, 1282, 1306, 1474, 1479, 1534…\n\n\n.\n\nNotes\n\nWhat if I wanted to make ‘year’ into intervals of decades/centuries/half centuries and then make them into factors?\nArvind says “console&gt; ? case_when&gt; enter”\nWhat does the numerical output of count(sex) mean when grouped by year? Is it the count of only one sex? Or Both?\n\n\n.\n."
  },
  {
    "objectID": "posts/Day 2/index.html#looking-at-star-trek-data-set",
    "href": "posts/Day 2/index.html#looking-at-star-trek-data-set",
    "title": "Day 2: Summaries",
    "section": "Looking at Star Trek Data Set:",
    "text": "Looking at Star Trek Data Set:\n\nstar_trek_data &lt;- read_csv(\"../../Data/star_trek_books.csv\")\nstar_trek_data\n\n\nstar_trek_data &lt;- read_delim(file = \"../../Data/star_trek_books.csv\", delim = \";\")\n\nRows: 783 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (7): title, author, publisher, identifier, series, subseries, dedication\ndbl  (3): nchap, nword, nchar\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nstar_trek_data\n\n# A tibble: 783 × 11\n   title    author date       publisher identifier series subseries nchap  nword\n   &lt;chr&gt;    &lt;chr&gt;  &lt;date&gt;     &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n 1 Star Tr… Alan … 2009-05-12 Simon an… 1439163391 AV     &lt;NA&gt;         18  77035\n 2 Starfle… Rick … 2010-11-02 Simon Sp… 978144241… AV     Starflee…    14  40129\n 3 Starfle… Rudy … 2010-12-28 Simon Sp… 978144241… AV     Starflee…    31  52547\n 4 Starfle… Rick … 2011-06-28 Simon Sp… 978144241… AV     Starflee…    13  39495\n 5 Starfle… Alan … 2012-06-26 Simon Sp… 978144242… AV     Starflee…    30  62030\n 6 Star Tr… Alan … 2013-05-21 Gallery … 978147671… AV     &lt;NA&gt;         17  77438\n 7 Captain… James… 1998-06-01 Pocket B… 978143910… CT     &lt;NA&gt;         21  95110\n 8 Captain… Macke… 1998-10-01 Pocket B… 978074345… CT     &lt;NA&gt;         26  76392\n 9 Captain… Chris… 1998-10-01 Pocket B… 978143910… CT     &lt;NA&gt;         34  78678\n10 The Cap… John … 2000-03-01 Pocket B… 978074340… CT     &lt;NA&gt;        176 436682\n# ℹ 773 more rows\n# ℹ 2 more variables: nchar &lt;dbl&gt;, dedication &lt;chr&gt;\n\n\n.\n\nNotes\n\n.csv files read commas as separators.\nWhen faced with any other kind of separators, use “read_delim”, default for that is semicolon\n\n\n.\n\nstar_trek_data %&gt;% glimpse()\n\nRows: 783\nColumns: 11\n$ title      &lt;chr&gt; \"Star Trek: Star Trek Movie Tie-In\", \"Starfleet Academy: Th…\n$ author     &lt;chr&gt; \"Alan Dean Foster\", \"Rick Barba\", \"Rudy Josephs\", \"Rick Bar…\n$ date       &lt;date&gt; 2009-05-12, 2010-11-02, 2010-12-28, 2011-06-28, 2012-06-26…\n$ publisher  &lt;chr&gt; \"Simon and Schuster\", \"Simon Spotlight\", \"Simon Spotlight\",…\n$ identifier &lt;chr&gt; \"1439163391\", \"9781442414259\", \"9781442414242\", \"9781442414…\n$ series     &lt;chr&gt; \"AV\", \"AV\", \"AV\", \"AV\", \"AV\", \"AV\", \"CT\", \"CT\", \"CT\", \"CT\",…\n$ subseries  &lt;chr&gt; NA, \"Starfleet Academy\", \"Starfleet Academy\", \"Starfleet Ac…\n$ nchap      &lt;dbl&gt; 18, 14, 31, 13, 30, 17, 21, 26, 34, 176, 9, 12, 36, 23, 44,…\n$ nword      &lt;dbl&gt; 77035, 40129, 52547, 39495, 62030, 77438, 95110, 76392, 786…\n$ nchar      &lt;dbl&gt; 460097, 238567, 295829, 233095, 349595, 537472, 554915, 424…\n$ dedication &lt;chr&gt; \"For Bjo and John TrimbleBecause hospitality is forever and…\n\n\n\nMaking an easy-to-read Table:\n\n## removig the last coloumn for the sake of readability\nstartrek_data_mod &lt;- star_trek_data %&gt;%\n  select(-dedication)\n\n## formatting table for better readability\nstartrek_data_mod %&gt;%\n  head(20) %&gt;%\n  kbl(\n    # add Human Readable column names\n    col.names = c(\n      \"Title\", \"Author\", \"Date\",\n      \"Publisher\", \"Identifier\", \"Series\",\n      \"Subseries\", \"Number\\n of\\n Chapters\", \"Number\\n of\\n Words\",\n      \"Number\\n of\\n Characters\"\n    ),\n    caption = \"Startrek Dataset\"\n  ) %&gt;%\n  kable_styling(\n    bootstrap_options = c(\n      \"striped\", \"hover\",\n      \"condensed\", \"responsive\"\n    ),\n    full_width = F, position = \"center\"\n  )\n\n\n\nStartrek Dataset\n\n\nTitle\nAuthor\nDate\nPublisher\nIdentifier\nSeries\nSubseries\nNumber of Chapters\nNumber of Words\nNumber of Characters\n\n\n\n\nStar Trek: Star Trek Movie Tie-In\nAlan Dean Foster\n2009-05-12\nSimon and Schuster\n1439163391\nAV\nNA\n18\n77035\n460097\n\n\nStarfleet Academy: The Delta Anomaly\nRick Barba\n2010-11-02\nSimon Spotlight\n9781442414259\nAV\nStarfleet Academy\n14\n40129\n238567\n\n\nStarfleet Academy: The Edge\nRudy Josephs\n2010-12-28\nSimon Spotlight\n9781442414242\nAV\nStarfleet Academy\n31\n52547\n295829\n\n\nStarfleet Academy: The Gemini Agent\nRick Barba\n2011-06-28\nSimon Spotlight\n9781442414266\nAV\nStarfleet Academy\n13\n39495\n233095\n\n\nStarfleet Academy: The Assassination Game\nAlan Gratz\n2012-06-26\nSimon Spotlight\n9781442420601\nAV\nStarfleet Academy\n30\n62030\n349595\n\n\nStar Trek: Into Darkness\nAlan Dean Foster\n2013-05-21\nGallery Books\n9781476716510\nAV\nNA\n17\n77438\n537472\n\n\nCaptain's Table 1: War Dragons\nJames T. Hirk\n1998-06-01\nPocket Books\n9781439108512\nCT\nNA\n21\n95110\n554915\n\n\nCaptain's Table 5: Once Burned\nMackenzie\n1998-10-01\nPocket Books\n9780743455787\nCT\nNA\n26\n76392\n424689\n\n\nCaptain's Table 6: Where Sea Meets Sky\nChristopher Pike\n1998-10-01\nPocket Books\n9781439108536\nCT\nNA\n34\n78678\n443307\n\n\nThe Captain's Table 1-6 (Omnibus)\nJohn J. Ordover and Dean Wesley Smith\n2000-03-01\nPocket Books\n9780743406703\nCT\nNA\n176\n436682\n2466047\n\n\nTales from the Captain's Table\nKeith R.A. Decandido\n2005-06-14\nPocket Books\n9781416510284\nCT\nNA\n9\n101577\n588475\n\n\nEmissary\nJ. M. Dillard\n1993-02-01\nPocket Books\n0743412206\nDS9\nNA\n12\n60903\n368047\n\n\nThe Siege\nPeter David\n1993-05-01\nSimon and Schuster\n9780743412216\nDS9\nNA\n36\n73075\n438146\n\n\nBloodletter\nK.W. Jeter\n1993-08-01\nPocket Books\n9780743412223\nDS9\nNA\n23\n69797\n404217\n\n\nThe Big Game\nSandy Schofield\n1993-11-01\nPocket Books\n9780743412230\nDS9\nNA\n44\n62085\n348583\n\n\nFallen Heroes\nDafydd Ab Hugh\n1994-02-01\nPocket Books\n9780671041144\nDS9\nNA\n20\n82087\n480570\n\n\nBetrayal\nLois Tilton\n1994-05-01\nSimon and Schuster\n9780743420341\nDS9\nNA\n30\n69441\n411458\n\n\nWarchild\nEsther Friesner\n1994-09-01\nSimon and Schuster\n9780743420389\nDS9\nNA\n17\n83047\n467694\n\n\nThe Search\nDiane Carey\n1994-10-01\nSimon and Schuster\n9780743420815\nDS9\nNA\n19\n62364\n356249\n\n\nAntimatter\nJohn Vornholt\n1994-11-01\nSimon and Schuster\n9780743420396\nDS9\nNA\n16\n70493\n415964\n\n\n\n\n\n\n\n\n\nstar_trek_data %&gt;% inspect()\n\n\ncategorical variables:  \n        name     class levels   n missing\n1      title character    781 783       0\n2     author character    277 783       0\n3  publisher character     21 772      11\n4 identifier character    783 783       0\n5     series character     28 783       0\n6  subseries character     15  56     727\n7 dedication character    372 372     411\n                                   distribution\n1 Kobayashi Maru (0.3%), Warped (0.3%) ...     \n2 Peter David (4.9%) ...                       \n3 Pocket Books (67.4%) ...                     \n4  (%) ...                                     \n5 TOS (26.8%), TNG (18.6%), SCE (10.7%) ...    \n6 Typhon Pact (16.1%) ...                      \n7  (%) ...                                     \n\nDate variables:  \n  name class      first       last min_diff max_diff   n missing\n1 date  Date 1967-01-01 2017-11-28   0 days 485 days 783       0\n\nquantitative variables:  \n   name   class  min     Q1 median       Q3     max         mean           sd\n1 nchap numeric    1     13     21     29.0     373     24.58816     21.61247\n2 nword numeric  782  52500  70730  90994.5  687175  76190.07535  52453.34633\n3 nchar numeric 4337 310520 415964 555866.5 4484069 461822.36271 326062.44928\n    n missing\n1 760      23\n2 783       0\n3 783       0\n\n\n\nstar_trek_data %&gt;% skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n783\n\n\nNumber of columns\n11\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n7\n\n\nDate\n1\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ntitle\n0\n1.00\n4\n58\n0\n781\n0\n\n\nauthor\n0\n1.00\n2\n138\n0\n277\n0\n\n\npublisher\n11\n0.99\n7\n26\n0\n21\n0\n\n\nidentifier\n0\n1.00\n10\n41\n0\n783\n0\n\n\nseries\n0\n1.00\n2\n6\n0\n28\n0\n\n\nsubseries\n727\n0.07\n4\n23\n0\n15\n0\n\n\ndedication\n411\n0.48\n98\n97953\n0\n372\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndate\n0\n1\n1967-01-01\n2017-11-28\n2001-12-14\n577\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nnchap\n23\n0.97\n24.59\n21.61\n1\n13\n21\n29.0\n373\n▇▁▁▁▁\n\n\nnword\n0\n1.00\n76190.08\n52453.35\n782\n52500\n70730\n90994.5\n687175\n▇▁▁▁▁\n\n\nnchar\n0\n1.00\n461822.36\n326062.45\n4337\n310520\n415964\n555866.5\n4484069\n▇▁▁▁▁\n\n\n\n\n\n.\n."
  },
  {
    "objectID": "posts/Day 2/index.html#munging-star-trek-data",
    "href": "posts/Day 2/index.html#munging-star-trek-data",
    "title": "Day 2: Summaries",
    "section": "Munging Star Trek Data:",
    "text": "Munging Star Trek Data:\n\n## grouping by publisher to understand the average of certain quant variables\nstartrek_munged &lt;- star_trek_data %&gt;%\n  group_by(publisher) %&gt;%\n  summarize(avg_nchap = mean(nchap), avg_nw = mean(nword), avg_nchar = mean(nchar), count = n())\n\n## creating a readable table for this summary\nstartrek_munged %&gt;%\n  head(20) %&gt;%\n  kbl(\n    col.names = c(\n      \"Publisher\",\"Average\\n #of\\n Chapters\", \"Average\\n #of\\n Words\", \"Average\\n #of\\n Characters\",\n      \"Total\\n #of\\n Books\"\n    ),\n    caption = \"Startrek Dataset - Munged\"\n  ) %&gt;%\n  column_spec(1 , border_right = TRUE) %&gt;%\n  kable_styling(\n    bootstrap_options = c(\n      \"striped\", \"hover\",\n      \"condensed\", \"responsive\"\n    ),\n    full_width = F, position = \"center\"\n  )\n\n\n\nStartrek Dataset - Munged\n\n\nPublisher\nAverage #of Chapters\nAverage #of Words\nAverage #of Characters\nTotal #of Books\n\n\n\n\nAbrams Publications\n373.00000\n132041.00\n898671.0\n1\n\n\nAladdin\n11.25000\n23800.71\n139129.2\n28\n\n\nAladdin Paperbacks\n24.00000\n69076.00\n390799.0\n1\n\n\nAmereon Ltd\nNA\n40804.50\n233809.0\n2\n\n\nBantam Books\nNA\n50225.20\n287110.7\n20\n\n\nDemco Media\n6.50000\n23310.50\n134614.0\n2\n\n\nDk Publishing\n1.00000\n119459.00\n1094928.0\n1\n\n\nElysium\n21.00000\n98779.00\n578010.0\n1\n\n\nGallery Books\n34.13333\n93417.67\n613744.8\n15\n\n\nHarlequin\n27.00000\n63453.00\n372682.0\n1\n\n\nInsight Editions\n43.00000\n32915.00\n239389.5\n2\n\n\nKlingon Language Institute\n14.00000\n58231.00\n417503.0\n1\n\n\nKrause Publications\nNA\n58073.00\n390642.0\n1\n\n\nPocket Books\nNA\n79750.91\n485790.7\n520\n\n\nSimon Pulse\n32.00000\n76558.00\n450457.0\n1\n\n\nSimon Spotlight\n22.00000\n48550.25\n279271.5\n4\n\n\nSimon and Schuster\nNA\n76054.30\n450020.9\n159\n\n\nSpectra\nNA\n67716.00\n391634.3\n3\n\n\nSt. Martin's Press\nNA\n273792.50\n1627148.0\n2\n\n\nTitan Books\nNA\n69734.67\n429937.3\n6\n\n\n\n\n\n\n\n\n\n##star_trek_data %&gt;% \n  ##group_by(publisher) %&gt;% \n  ##gitsummarize(author_count = sum(author))\n\n.\n."
  },
  {
    "objectID": "posts/Day 2/index.html#conclusion",
    "href": "posts/Day 2/index.html#conclusion",
    "title": "Day 2: Summaries",
    "section": "Conclusion:",
    "text": "Conclusion:"
  },
  {
    "objectID": "posts/Day 5.B/index.html",
    "href": "posts/Day 5.B/index.html",
    "title": "Day 5: Change",
    "section": "",
    "text": "in functions under change:\n\nselect(where())\ngf_point()\ngf_lm()\nGGgalley::ggpairs ()\n\ncoloums =\nswitch =\nprogress =\ndiag =\nlower =\nlist()\nwrap()\n\nmosaic::cor_test()\nbroom::tidy()\nknitr::kable\n\ndigits\ncaption\n\ncorrelation::correlation()\ngf_errorbar()\ngf_hline()\ngf_smooth()\nggExtra::ggMarginal"
  },
  {
    "objectID": "posts/Day 5.B/index.html#introduction",
    "href": "posts/Day 5.B/index.html#introduction",
    "title": "Day 5: Change",
    "section": "",
    "text": "in functions under change:\n\nselect(where())\ngf_point()\ngf_lm()\nGGgalley::ggpairs ()\n\ncoloums =\nswitch =\nprogress =\ndiag =\nlower =\nlist()\nwrap()\n\nmosaic::cor_test()\nbroom::tidy()\nknitr::kable\n\ndigits\ncaption\n\ncorrelation::correlation()\ngf_errorbar()\ngf_hline()\ngf_smooth()\nggExtra::ggMarginal"
  },
  {
    "objectID": "posts/Final Reflection/index.html",
    "href": "posts/Final Reflection/index.html",
    "title": "(11) And Finally…..",
    "section": "",
    "text": "As I began writing what would be the last reflection for this class, a thought occurred to me. What better way to finally reflect, if not with graphs?\n.\nFirst I ranked each day of the course out of 10 on my understanding of the course material, my learnings and my joy levels. The following is a rundown of my code process to get to the graphs from this data, and then finally, my final final reflection :)\n.\nDISCLAIMER! - all inferences and data uncovered on this page must be taken with a mighty grain of salt. I’ve defined the rankings, and if anything, im a bit of a va-riable myself.\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(ggbump)\nlibrary(ggplot2)\nlibrary(DT)\nlibrary(corrplot)\n\ncorrplot 0.95 loaded\n\nlibrary(broom)\n\n.\n\n## reading data\nreflection &lt;- read_csv(file =\"../../Data/reflection.csv\")\n\nRows: 10 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): label\ndbl (4): day, learning, understanding, joy\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "posts/Final Reflection/index.html#introduction",
    "href": "posts/Final Reflection/index.html#introduction",
    "title": "(11) And Finally…..",
    "section": "",
    "text": "As I began writing what would be the last reflection for this class, a thought occurred to me. What better way to finally reflect, if not with graphs?\n.\nFirst I ranked each day of the course out of 10 on my understanding of the course material, my learnings and my joy levels. The following is a rundown of my code process to get to the graphs from this data, and then finally, my final final reflection :)\n.\nDISCLAIMER! - all inferences and data uncovered on this page must be taken with a mighty grain of salt. I’ve defined the rankings, and if anything, im a bit of a va-riable myself.\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(ggformula)\nlibrary(skimr)\n\n\nAttaching package: 'skimr'\n\nThe following object is masked from 'package:mosaic':\n\n    n_missing\n\nlibrary(ggbump)\nlibrary(ggplot2)\nlibrary(DT)\nlibrary(corrplot)\n\ncorrplot 0.95 loaded\n\nlibrary(broom)\n\n.\n\n## reading data\nreflection &lt;- read_csv(file =\"../../Data/reflection.csv\")\n\nRows: 10 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): label\ndbl (4): day, learning, understanding, joy\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "posts/Final Reflection/index.html#code",
    "href": "posts/Final Reflection/index.html#code",
    "title": "(11) And Finally…..",
    "section": "Code",
    "text": "Code\n\nData:\n\n## data overview, as I initially input it\ndatatable(reflection, options = list(pageLength = 10))\n\n\n\n\n\n.\n\nreflection %&gt;% glimpse()\n\nRows: 10\nColumns: 5\n$ day           &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n$ learning      &lt;dbl&gt; 10, 10, 10, 10, 9, NA, 10, 10, 9, 6\n$ understanding &lt;dbl&gt; 9, 10, 10, 10, 6, NA, 6, 7, 9, 5\n$ joy           &lt;dbl&gt; 10, 10, 10, 10, 7, NA, 7, 6, 7, 5\n$ label         &lt;chr&gt; \"intro\", \"summaries\", \"counts\", \"quant\", \"groups, change…\n\n\n.\n\nreflection %&gt;% inspect()\n\n\ncategorical variables:  \n   name     class levels  n missing\n1 label character      9 10       0\n                                   distribution\n1 stats theory (20%), a3 (10%) ...             \n\nquantitative variables:  \n           name   class min   Q1 median    Q3 max     mean       sd  n missing\n1           day numeric   1 3.25    5.5  7.75  10 5.500000 3.027650 10       0\n2      learning numeric   6 9.00   10.0 10.00  10 9.333333 1.322876  9       1\n3 understanding numeric   5 6.00    9.0 10.00  10 8.000000 2.000000  9       1\n4           joy numeric   5 7.00    7.0 10.00  10 8.000000 2.000000  9       1\n\n\n.\n\nreflection %&gt;% skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n10\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nlabel\n0\n1\n2\n15\n0\n9\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nday\n0\n1.0\n5.50\n3.03\n1\n3.25\n5.5\n7.75\n10\n▇▇▇▇▇\n\n\nlearning\n1\n0.9\n9.33\n1.32\n6\n9.00\n10.0\n10.00\n10\n▁▁▁▂▇\n\n\nunderstanding\n1\n0.9\n8.00\n2.00\n5\n6.00\n9.0\n10.00\n10\n▇▂▁▅▇\n\n\njoy\n1\n0.9\n8.00\n2.00\n5\n7.00\n7.0\n10.00\n10\n▃▆▁▁▇\n\n\n\n\n\n.\n.\n\n\nGraphs:\n\n## average of parameters across 10 days\nreflection %&gt;%\n  drop_na() %&gt;% \n  mutate( day = as_factor(day)) %&gt;%\n  summarize(learning = mean(learning),\n            understanding = mean(understanding),\n            joy = mean(joy)) %&gt;%\n   pivot_longer(cols = c(\"learning\", \"understanding\", \"joy\"),\n                    cols_vary = \"slowest\",\n                    names_to = \"parameter\",\n                    values_to =\"meanvalue\") %&gt;%\n  gf_col(meanvalue ~parameter,\n         fill = ~parameter\n  ) %&gt;% \n  gf_refine(scale_fill_manual(values = c(\"learning\" = \"violet\", \"understanding\" = \"purple\", \"joy\" = \"pink\"))) %&gt;% \n  gf_labs(\n    title = \"Plot 1: Overall Parameters\",\n    caption = \"25th October, 2024\"\n  )\n\n\n\n\n\n\n\n\n.\n\nInference 1\nWell, I seemed to have learned quite a lot, but haven’t fully understood all I’ve learned. The joy in my learning is about as much as my understanding.\n.\n.\n\n## modifying data for stacked graphs\n\nreflection_mod &lt;- reflection %&gt;%\n  drop_na() %&gt;% \n  mutate( day = as_factor(day)) %&gt;% \n  pivot_longer(cols = c(\"learning\", \"understanding\", \"joy\"),\n                    cols_vary = \"slowest\",\n                    names_to = \"parameter\",\n                    values_to =\"values\") %&gt;% glimpse()\n\nRows: 27\nColumns: 4\n$ day       &lt;fct&gt; 1, 2, 3, 4, 5, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 8, 9, 10, 1, 2…\n$ label     &lt;chr&gt; \"intro\", \"summaries\", \"counts\", \"quant\", \"groups, change\", \"…\n$ parameter &lt;chr&gt; \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", …\n$ values    &lt;dbl&gt; 10, 10, 10, 10, 9, 10, 10, 9, 6, 9, 10, 10, 10, 6, 6, 7, 9, …\n\n\n.\n\n## Looking at the distribution of parameters\n\nreflection_mod %&gt;% \n  gf_col(day~values,\n         fill = ~parameter) %&gt;% \n   gf_refine(scale_fill_manual(values = c(\"learning\" = \"violet\", \"understanding\" = \"purple\", \"joy\" = \"pink\"))) %&gt;% \n  gf_labs(\n    title = \"Plot 2: Distribution of  Parameters\",\n    subtitle = \"Stacked Graph\",\n    caption = \"25th October, 2024\"\n  )\n\n\n\n\n\n\n\n\n.\n\n\nInference 2\nAll three parameters gradually decreased as the days went on. Was this because I realized that we wouldn’t be able to cover as much as I thought we would? Or was it because work picked up in terms of the cycle and I couldn’t focus? Even I’m not entirely sure.\n.\n.\n\n## Looking at proportions for each day\nreflection_mod %&gt;% \n  gf_col(day~values,\n         fill = ~parameter,\n         position = \"fill\") %&gt;% \n   gf_refine(scale_fill_manual(values = c(\"learning\" = \"violet\", \"understanding\" = \"purple\", \"joy\" = \"pink\"))) %&gt;% \n  gf_labs(\n    title = \"Plot 3: Proportion Distribution of Parameters\",\n    subtitle = \"Filled Graph\",\n    caption = \"25th October, 2024\"\n  )\n\n\n\n\n\n\n\n\n.\n\n\nInference 3\nThe proportion of my joy, understanding and learning for each day seem to stay in the realm of each other, with nothing too extreme. Sure, there’s definitely differences, but its safe to say that I expected and experienced the same of each day.\n.\nInteresting.\n.\nThis means that even though I expected the same of each day, I didn’t expect the same over 12 days, since I felt we couldn’t cover as much. I guess this goes to say what a terrible long term judgement I have, oof :’)\n.\n.\n\n## Looking at each parameter indivdually\nreflection_mod %&gt;% \n  gf_col(day~values,\n         fill = ~parameter) %&gt;% \n  gf_facet_wrap(~parameter) %&gt;% \n   gf_refine(scale_fill_manual(values = c(\"learning\" = \"violet\", \"understanding\" = \"purple\", \"joy\" = \"pink\"))) %&gt;% \n  gf_labs(\n    title = \"Plot 4:  Individual Parameters by Day\",\n    subtitle = \"Facet Wrapped\",\n    caption = \"25th October, 2024\"\n  )\n\n\n\n\n\n\n\n\n.\n\n\nInference 4\nWith the most gradual decline being joy and the most ups and downs in understanding, even if their averages are the same, its clear to see that learning was the most consistent (even if it followed similar trends) through the days. Nice!\n.\n.\n\n## Attempting a Bump Chart\n\nggplot(reflection_mod, aes(x = parameter, y = values, color = day, group = day)) +\n  geom_bump(size = 1) +  \n  geom_point(size = 4) +  \n  scale_x_discrete(\n    limits = c(  \"learning\", \"understanding\",\"joy\"),\n    labels = c( \"learning\", \"understanding\",\"joy\" )\n    ) + \n  labs(title = \"Plot 5: Bump Chart Ranked by Parameter\",\n       caption = \"25th October, 2024\",\n       x = \"Parameters\",\n       y = \"Rank\",\n       color = \"\") +\n  scale_color_brewer(palette = \"RdPu\") +\n  theme(axis.text.x = element_text(angle = 0, hjust = 0.1))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n.\n\n\nInference 5\nThe graph seems to have completely omitted rankings below 5, as all my rankings were 5 and above. In my experience, this class was above average, on the whole! Perhaps this isn’t the best way to visualize this information, but it clearly sets apart the days with the most difference in ranking across parameter. Day 7, the first day of Stats Theory, must have really taken me by surprise.\n.\n.\n\n## How about the other way?\nggplot(reflection_mod, aes(x = day, y = values, color = parameter, group = parameter)) +\n  geom_bump(size = 1) +  \n  geom_point(size = 4) +  \n  scale_x_discrete(\n    limits = c(\"1\", \"2\",\"3\",\"4\",\"5\",\"7\",\"8\",\"9\",\"10\"),\n    labels = c(\"D1\", \"D2\",\"D3\",\"D4\",\"D5\",\"D7\",\"D8\",\"D9\",\"D10\" )\n    ) + \n  labs(title = \"Plot 6: Bump Chart ranked by Day\",\n       caption = \"25th October, 2024\",\n       x = \"Day\",\n       y = \"Ranks on 10\",\n       color = \"Parameter\") +\n  scale_color_brewer(palette = \"RdPu\")+\n  theme(axis.text.x = element_text(angle = 0, hjust = 0.1)) \n\n\n\n\n\n\n\n\n.\n\n\nInference 6\nThe other way in which a Bump Chart can be used for this data, it only confirms what we (I) have understood about myself.\n.\n.\n\n## correlation test for learning and understanding\nmosaic::cor_test(learning ~ understanding, data = reflection) %&gt;%\n  broom::tidy() %&gt;%\n  knitr::kable(\n    digits = 2,\n    caption = \"learning vs understanding\"\n  )\n\n\nlearning vs understanding\n\n\n\n\n\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\n\n0.61\n2.06\n0.08\n7\n-0.08\n0.91\nPearson’s product-moment correlation\ntwo.sided\n\n\n\n\n\n.\n\n## plotting correlation\nreflection %&gt;% \n  gf_point(learning ~ understanding) %&gt;%\n  gf_lm(color = \"violet\") %&gt;%\n  gf_labs(title = \"Plot 7: Correlation between understanding and learning\",\n          x = \"understanding\",\n          y = \"learning\")\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_lm()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Using the `size` aesthetic with geom_line was deprecated in ggplot2 3.4.0.\nℹ Please use the `linewidth` aesthetic instead.\n\n\n\n\n\n\n\n\n\n.\n\n\nInference 7\nAs seen in the upwards slope of the graph, my learning and understanding have a positive correlation, with an estimate on 0.61. However, the confidence intervals include 0, indicating that it is not a significant correlation. We can’t say for sure if my learning and understanding always depend on each other!\n.\n."
  },
  {
    "objectID": "posts/Final Reflection/index.html#final-reflection",
    "href": "posts/Final Reflection/index.html#final-reflection",
    "title": "(11) And Finally…..",
    "section": "Final (?) Reflection",
    "text": "Final (?) Reflection\nThis week really didn’t feel like the final week of class. Somehow, there is still so much more in the realm of R to be explored – I’m only just realizing that 12 days is barely anything in terms of the learning curve. Apart from R and RStudio, this class has taught me various things.\n.\n\nA blog for the web need not have to be some tediously hand-coded HTML document – the versatility of quarto takes care of all that.\n.\n\n\n\nI think I will also forever look at excel sheets differently; the potential in all those columns and rows for some seriously good art!\n\n.\n\nProviding incentive goes a long way, acting as a catalyst for efficiency in data collection. Even better when the costs are shared, it’s definitely a good investment.\n.\nGood design is informed by solid data. Hypothesis developed from the very same data is often built on pretences. That does not mean the conclusion isn’t credible: oftentimes, hypotheses are made up to be disproved, since doing the opposite isn’t feasible.\n.\n\nSafe to say, this class has also left me with some questions:\n.\n\nEliminating bias in terms of who the data is coming from is done with a coin toss. What about the data itself? How can a researcher account for false statements or partial truths?\n.\nTrust – in both data and research process begs the question of ethics. Collaborative environments are inevitable, and navigating through them is sometimes more complicated than figuring out R. I can account for myself, but what about situations where I make up one of many parts? My group, my class, my institution?\n.\n\nCollecting data ourselves was a lot more fun than I thought it would be. Generally, the thought of approaching random people acts as repellent enough from the task assigned, but just a few interviews in, the chocolates seemed to be performing their magic. It was also comforting to know that it did not matter who I approached – all was decided by the flip of a coin. The coin toss also became this sort of identifier: many guessed with an “Oh, are you in Arvind’s class?” before the question was even asked.\n.\nThis won’t be goodbye, as there’s the whole of A3 to power through and hopefully some online classes as well. Super excited about all the resources I now have, especially those to pore over maps!!"
  }
]